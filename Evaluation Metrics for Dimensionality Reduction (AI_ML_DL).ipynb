{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMMOTNATYT/frf6gqw5iugl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ðŸ“œ Evaluation Metrics for Dimensionality Reduction (AI/ML/DL)\n","\n","---\n","\n","## ðŸ”¹ 1. Classical ML Metrics\n","\n","**Reconstruction Error (PCA, Autoencoders):**\n","\n","$$\n","L = \\|X - \\hat{X}\\|^2\n","$$\n","\n","Measures how well the original input can be reconstructed.\n","\n","---\n","\n","**Explained Variance Ratio (PCA):**\n","\n","$$\n","\\text{Explained Variance} = \\frac{\\text{Var}(X_{\\text{reduced}})}{\\text{Var}(X)}\n","$$\n","\n","Fraction of total variance captured by reduced components.\n","\n","---\n","\n","**Stress (MDS):**\n","\n","$$\n","\\text{Stress} = \\frac{\\sum (d_{ij}^{HD} - d_{ij}^{LD})^2}{\\sum (d_{ij}^{HD})^2}\n","$$\n","\n","Measures preservation of pairwise distances.\n","\n","---\n","\n","## ðŸ”¹ 2. Manifold Learning Metrics\n","\n","**Trustworthiness (Kaski & Venna, 2001):**  \n","Measures how many neighbors in low-d space are true neighbors in high-d.\n","\n","**Continuity:**  \n","Reverse of trustworthiness â†’ how many high-d neighbors are preserved in low-d.\n","\n","**Mean Relative Rank Error (MRRE):**  \n","Quantifies how well neighborhood ranks are preserved.\n","\n","**Local Continuity Meta-Criterion (LCMC):**  \n","Compares overlap of $k$-nearest neighbors between spaces.\n","\n","---\n","\n","## ðŸ”¹ 3. Information-Theoretic Metrics\n","\n","**KL Divergence (t-SNE):**\n","\n","$$\n","KL(P^{HD} \\parallel Q^{LD})\n","$$\n","\n","Preserves local neighbor probability distributions.\n","\n","---\n","\n","**Cross-Entropy (UMAP):**  \n","Loss based on matching fuzzy neighbor graphs.\n","\n","---\n","\n","**Mutual Information:**  \n","Measures shared structural information between original and reduced representations.\n","\n","---\n","\n","## ðŸ”¹ 4. Deep Learning Metrics\n","\n","**Autoencoder Losses:**  \n","MSE, Cross-Entropy, or KL terms (VAEs, Î²-VAEs).  \n","\n","**Clustering Performance (Downstream):**  \n","Apply clustering â†’ measure **NMI, ARI, Purity**.  \n","\n","**Classification Accuracy (Downstream):**  \n","Train classifier on embeddings â†’ measure **Accuracy, F1**.  \n","\n","---\n","\n","## ðŸ”¹ 5. Visualization & Perceptual Metrics\n","\n","**Neighborhood Preservation (NP@k):**  \n","Fraction of top-$k$ neighbors preserved.  \n","\n","**Shepard Diagram Correlation:**  \n","Correlation of pairwise distances (HD vs LD).  \n","\n","**Stress Per Point (SPP):**  \n","Local stress per datapoint.  \n","\n","**Visual Inspection (plots):**  \n","Often used qualitatively (t-SNE, UMAP scatterplots).  \n","\n","---\n","\n","## âœ… Summary Families\n","\n","- **Reconstruction metrics:** Error, explained variance â†’ PCA, AEs.  \n","- **Distance preservation:** Stress, Shepard correlation â†’ MDS.  \n","- **Neighborhood preservation:** Trustworthiness, Continuity, MRRE, LCMC â†’ t-SNE, UMAP.  \n","- **Information-theoretic:** KL divergence (t-SNE), cross-entropy (UMAP).  \n","- **Task-based (downstream):** Classification (Accuracy, F1), Clustering (ARI, NMI).  \n"],"metadata":{"id":"G7fUdGJn6tg-"}},{"cell_type":"markdown","source":["# ðŸ“Š Comparative Table: Dimensionality Reduction Evaluation Metrics (AI/ML/DL)\n","\n","| Metric                          | Formula (simplified)                                                                 | Intuition                                | Pros                              | Cons                                    | When to Use                  |\n","|---------------------------------|--------------------------------------------------------------------------------------|------------------------------------------|-----------------------------------|-----------------------------------------|-------------------------------|\n","| **Reconstruction Error (PCA/AE)** | $$\\|X - \\hat{X}\\|^2$$                                                                 | Measures how well original data is reconstructed | Simple, intuitive                 | Doesnâ€™t measure structure preservation | Autoencoders, PCA             |\n","| **Explained Variance Ratio (PCA)** | $$\\frac{\\text{Var}(X_{\\text{reduced}})}{\\text{Var}(X)}$$                              | How much variance is captured             | Clear interpretability             | Linear only                            | PCA, linear DR                |\n","| **Stress (MDS)**                | $$\\frac{\\sum (d_{ij}^{HD} - d_{ij}^{LD})^2}{\\sum (d_{ij}^{HD})^2}$$                   | Preserves pairwise distances              | Good for distance-based DR         | Costly on large $n$                    | MDS, Isomap                   |\n","| **Shepard Diagram Correlation** | $$\\text{Corr}(d^{HD}, d^{LD})$$                                                       | Correlation of distances                  | Intuitive                          | No single score                        | Distance preservation tasks   |\n","| **Trustworthiness**             | Penalizes non-neighbors in LD space                                                   | How many LD neighbors are true HD neighbors | Captures local preservation        | Ignores global                         | t-SNE, UMAP embeddings        |\n","| **Continuity**                  | Reverse of trustworthiness                                                            | HD neighbors preserved in LD              | Complements trustworthiness        | Ignores false neighbors                | Local manifold DR             |\n","| **MRRE (Mean Relative Rank Error)** | Avg. rank mismatch between HD & LD neighbors                                         | Preserves rank order                      | Detailed neighborhood quality      | Harder to interpret                     | Nonlinear DR                  |\n","| **LCMC (Local Continuity Meta-Criterion)** | Overlap of $k$-NN sets                                                           | Captures neighborhood overlap             | Intuitive                          | Sensitive to $k$                        | t-SNE/UMAP evaluation         |\n","| **KL Divergence (t-SNE)**       | $$KL(P^{HD} \\parallel Q^{LD})$$                                                       | Match neighbor distributions              | Optimized by t-SNE                 | Emphasizes local, not global           | t-SNE                         |\n","| **Cross-Entropy (UMAP)**        | $$-\\sum p_{ij}\\log q_{ij} + (1-p_{ij})\\log(1-q_{ij})$$                                | Match fuzzy neighbor graphs               | Captures local & global            | Sensitive to parameters                | UMAP embeddings               |\n","| **Mutual Information (MI)**     | MI between HD & LD spaces                                                             | Shared structural info                    | Information-theoretic              | Computationally expensive              | DR preserving global info     |\n","| **Clustering Accuracy (ACC)**   | $$ACC = \\max_{\\pi} \\frac{1}{n}\\sum 1[y_i = \\pi(c_i)]$$ (Hungarian matching)           | Aligns clusters with ground truth labels  | Direct interpretability            | Needs labels                           | AE/DEC embeddings             |\n","| **NMI / ARI / Purity (external)** | Standard clustering metrics on embeddings                                           | Evaluate latent clustering quality        | Well-standardized                  | Requires ground truth labels           | Downstream clustering tasks   |\n","| **Classification Accuracy (external)** | Classifier performance on reduced features                                       | Task-based evaluation                     | Practical                          | Needs labels                           | DR for supervised downstream  |\n","| **NP@k (Neighbor Preservation)** | Fraction of top-$k$ neighbors preserved                                               | Local neighborhood retention              | Easy to interpret                  | Needs $k$ choice                       | Embedding quality             |\n","| **Stress Per Point (SPP)**      | Localized stress per sample                                                           | Point-level quality metric                | Detailed per-point insight         | Less global interpretability           | DR error analysis             |\n","| **Visual Evaluation**           | Scatterplots (t-SNE/UMAP)                                                             | Intuitive cluster visualization           | Human-interpretable                | Subjective                             | Exploratory analysis           |\n","\n","---\n","\n","## âœ… Key Insights\n","\n","- **Reconstruction metrics** â†’ PCA, Autoencoders.  \n","- **Variance/distance metrics** â†’ Explained variance, Stress, Shepard correlation.  \n","- **Neighborhood metrics** â†’ Trustworthiness, Continuity, MRRE, LCMC.  \n","- **Info-theoretic metrics** â†’ KL (t-SNE), Cross-Entropy (UMAP), MI.  \n","- **Task-based metrics** â†’ ACC, NMI, ARI, Classification Accuracy.  \n","- **Visualization metrics** â†’ NP@k, SPP, scatterplots.  \n"],"metadata":{"id":"ElUcFYam7CTA"}}]}