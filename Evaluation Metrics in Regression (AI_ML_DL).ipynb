{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTR69Ny89Xz8UXnYKEX0Lk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üìú Evaluation Metrics in Regression (AI/ML/DL)\n","\n","---\n","\n","## üîπ 1. Error-Based Metrics\n","These measure the deviation between predicted ($\\hat{y}$) and true ($y$) values.\n","\n","- **Mean Absolute Error (MAE)**  \n","  $$\n","  MAE = \\frac{1}{n}\\sum |y - \\hat{y}|\n","  $$  \n","  ‚úÖ Robust to outliers  \n","  ‚ùå Doesn‚Äôt penalize large errors strongly  \n","\n","- **Mean Squared Error (MSE)**  \n","  $$\n","  MSE = \\frac{1}{n}\\sum (y - \\hat{y})^2\n","  $$  \n","  ‚úÖ Penalizes large errors heavily  \n","  ‚ùå Sensitive to outliers  \n","\n","- **Root Mean Squared Error (RMSE)**  \n","  $$\n","  RMSE = \\sqrt{MSE}\n","  $$  \n","  ‚úÖ Interpretable in original units  \n","  ‚ùå Same weaknesses as MSE  \n","\n","- **Mean Absolute Percentage Error (MAPE)**  \n","  $$\n","  MAPE = \\frac{100}{n}\\sum \\left|\\frac{y - \\hat{y}}{y}\\right|\n","  $$  \n","  ‚úÖ Scale-independent, percentage-based  \n","  ‚ùå Undefined if $y=0$, biased for small values  \n","\n","- **Symmetric MAPE (sMAPE)**  \n","  $$\n","  sMAPE = \\frac{100}{n}\\sum \\frac{|y - \\hat{y}|}{(|y|+|\\hat{y}|)/2}\n","  $$  \n","  ‚úÖ Better for forecasting  \n","  ‚ùå Still unstable near zero  \n","\n","---\n","\n","## üîπ 2. Relative Error Metrics\n","- **Mean Relative Error (MRE):** Average ratio of error to true value.  \n","- **Normalized RMSE (NRMSE):** RMSE divided by data range or mean.  \n","- **Relative Absolute Error (RAE):** Error relative to a baseline (e.g., predicting the mean).  \n","\n","---\n","\n","## üîπ 3. Goodness-of-Fit Metrics\n","- **$R^2$ (Coefficient of Determination)**  \n","  $$\n","  R^2 = 1 - \\frac{\\sum (y - \\hat{y})^2}{\\sum (y - \\bar{y})^2}\n","  $$  \n","  ‚úÖ Measures variance explained  \n","  ‚ùå Can be misleading for nonlinear models  \n","\n","- **Adjusted $R^2$**: Corrects $R^2$ for number of predictors.  \n","\n","---\n","\n","## üîπ 4. Robust Regression Metrics\n","- **Median Absolute Error:** Median of $|y - \\hat{y}|$.  \n","  ‚úÖ More robust than MAE  \n","\n","- **Quantile Loss (Pinball):** Used for quantile regression.  \n","  $$\n","  L_\\tau(r) = \\max(\\tau r, (\\tau-1) r)\n","  $$  \n","\n","- **Huber Loss (as evaluation):** Quadratic for small errors, linear for large.  \n","\n","---\n","\n","## üîπ 5. Forecasting & Time-Series Metrics\n","- **Mean Absolute Scaled Error (MASE):** Error relative to a naive baseline forecast.  \n","- **RMSSE (Root Mean Squared Scaled Error):** Used in forecasting competitions (M5).  \n","- **Theil‚Äôs U Statistic:** Compares forecast accuracy to naive model.  \n","\n","---\n","\n","## üîπ 6. Probabilistic Regression Metrics\n","Used when predicting distributions instead of point estimates.\n","\n","- **Negative Log Likelihood (NLL):** Penalizes likelihood of observed values.  \n","- **CRPS (Continuous Ranked Probability Score):** Compares predicted distribution to actual outcome.  \n","- **Calibration Metrics (Brier Score variants):** Evaluate probabilistic accuracy.  \n","\n","---\n","\n","## üîπ 7. Domain-Specific Metrics\n","- **Cosine Similarity / Geometric Losses:** For embeddings and vector regression.  \n","- **IoU / Dice Score (adapted):** Used when regression predicts structured outputs (e.g., bounding boxes).  \n","- **Perceptual Metrics:**  \n","  - **PSNR** (Peak Signal-to-Noise Ratio)  \n","  - **SSIM** (Structural Similarity)  \n","  Used in image and audio regression.  \n","\n","---\n","\n","## ‚úÖ Key Usage Scenarios\n","- **General regression:** MAE, MSE, RMSE, $R^2$  \n","- **Imbalanced scales / relative errors:** MAPE, sMAPE, NRMSE  \n","- **Outliers:** Median Absolute Error, Huber, quantile loss  \n","- **Forecasting:** MASE, RMSSE, Theil‚Äôs U  \n","- **Uncertainty-aware:** NLL, CRPS  \n","- **Images/audio:** PSNR, SSIM, perceptual losses  \n"],"metadata":{"id":"_lx3VvW3aoFP"}},{"cell_type":"markdown","source":["# üìä Comparative Table: Evaluation Metrics for Regression (AI/ML/DL)\n","\n","| Metric                                   | Formula (simplified)                                       | Intuition                      | Pros                            | Cons                                           | When to Use                         |\n","| ---------------------------------------- | ---------------------------------------------------------- | ------------------------------ | ------------------------------- | ---------------------------------------------- | ----------------------------------- |\n","| **MAE (Mean Absolute Error)**            | $$MAE = \\frac{1}{n}\\sum |y - \\hat{y}|$$                 | Average absolute deviation     | Robust to outliers, interpretable | Doesn‚Äôt penalize large errors strongly        | General regression, skewed data     |\n","| **MSE (Mean Squared Error)**             | $$MSE = \\frac{1}{n}\\sum (y - \\hat{y})^2$$                  | Penalizes squared deviations   | Smooth gradients, standard loss | Sensitive to outliers                          | Gaussian noise, stable datasets     |\n","| **RMSE (Root MSE)**                      | $$RMSE = \\sqrt{\\frac{1}{n}\\sum (y - \\hat{y})^2}$$          | Error in same units as target  | Easy interpretation             | Same outlier issues as MSE                     | Reporting performance               |\n","| **Median Absolute Error**                | $$\\text{MedAE} = \\text{median}(|y - \\hat{y}|)$$            | Median of errors               | Very robust to outliers          | Ignores variance of large errors               | Heavy-tailed noise                   |\n","| **MAPE (Mean Abs. Percentage Error)**    | $$MAPE = \\frac{100}{n}\\sum \\left|\\frac{y-\\hat{y}}{y}\\right|$$ | Percent error               | Scale-free, intuitive           | Undefined if $$y=0$$, biased when values small | Business/forecasting (nonzero y)    |\n","| **sMAPE (Symmetric MAPE)**               | $$sMAPE = \\frac{200}{n}\\sum \\frac{|y-\\hat{y}|}{|y|+|\\hat{y}|}$$ | Symmetric percentage error | Scale-free, handles symmetry    | Still unstable near zero values                | Time-series forecasting             |\n","| **RAE (Relative Abs. Error)**            | $$RAE = \\frac{\\sum |y-\\hat{y}|}{\\sum |y-\\bar{y}|}$$        | Error vs baseline (mean)       | Compares to naive model         | Needs meaningful baseline                      | Model comparison                    |\n","| **NRMSE (Normalized RMSE)**              | $$NRMSE = \\frac{RMSE}{\\max(y)-\\min(y)}$$                   | RMSE scaled by range/mean      | Dimensionless                   | Depends on normalization choice                | Comparing across datasets           |\n","| **R¬≤ (Coefficient of Determination)**    | $$R^2 = 1 - \\frac{\\sum (y-\\hat{y})^2}{\\sum (y-\\bar{y})^2}$$ | Variance explained             | Intuitive                       | Can be negative, misleading in nonlinear cases | Model fit in regression tasks       |\n","| **Adjusted R¬≤**                          | $$1-(1-R^2)\\frac{n-1}{n-p-1}$$                             | R¬≤ adjusted for features       | Penalizes overfitting           | Only valid for linear models                   | Feature selection evaluation        |\n","| **Huber Error**                          | $$L = \\begin{cases} \\tfrac{1}{2}r^2 & |r|\\le \\delta \\\\ \\delta(|r|-\\tfrac{1}{2}\\delta) & \\text{otherwise} \\end{cases}$$ | Blend of MSE & MAE | Robust to outliers, smooth | Requires Œ¥ tuning | Regression with moderate outliers |\n","| **RMSLE (Root Mean Squared Log Error)**  | $$RMSLE = \\sqrt{\\frac{1}{n}\\sum(\\log(1+y)-\\log(1+\\hat{y}))^2}$$ | Penalizes relative error | Handles exponential growth      | Undefined if $$y < -1$$                        | Growth prediction, finance          |\n","| **MASE (Mean Abs. Scaled Error)**        | $$MASE = \\frac{MAE}{MAE_{\\text{naive}}}$$                  | Error scaled by naive forecast | Scale-free, interpretable       | Needs baseline                                 | Forecasting competitions            |\n","| **RMSSE (Root MSE Scaled Error)**        | $$RMSSE = \\sqrt{\\frac{MSE}{MSE_{\\text{naive}}}}$$          | RMSE relative to naive         | Used in forecasting contests    | Needs seasonal baseline                        | Time-series (M5, Kaggle)            |\n","| **Theil‚Äôs U**                            | $$U = \\frac{RMSE}{RMSE_{\\text{naive}}}$$                   | Compare vs naive predictor     | Dimensionless                   | Limited interpretability                       | Economic/finance forecasts          |\n","| **Negative Log Likelihood (NLL)**        | $$NLL = -\\sum \\log p(y|\\hat{\\theta})$$                     | Probabilistic fit quality      | Models uncertainty              | Needs distribution assumption                  | Probabilistic regression            |\n","| **CRPS (Continuous Ranked Prob. Score)** | $$CRPS = \\int (F(y)-\\mathbb{1}(t\\le y))^2 dt$$             | Distributional accuracy        | Proper scoring rule             | Costly to compute                              | Probabilistic forecasting           |\n","| **Brier Score (adapted)**                | $$\\text{Brier} = \\frac{1}{n}\\sum (p-y)^2$$                 | Probabilistic calibration      | Easy to interpret               | Limited to [0,1] regression                    | Risk models, probability regression |\n","| **PSNR (Peak Signal-to-Noise Ratio)**    | $$PSNR = 10\\log_{10}\\frac{MAX^2}{MSE}$$                    | Signal reconstruction quality  | Perceptual for images           | Not task-general                               | Image/signal regression             |\n","| **SSIM (Structural Similarity Index)**   | Structural overlap function                               | Captures perceptual quality    | Correlates with human vision    | Non-convex, complex                            | Vision, denoising, generative tasks |\n","\n","---\n","\n","## ‚úÖ Key Takeaways\n","\n","- **General regression:** MAE, MSE, RMSE, R¬≤  \n","- **Outliers present:** Median Abs. Error, Huber  \n","- **Relative/scale-free:** MAPE, sMAPE, RAE, NRMSE  \n","- **Forecasting:** MASE, RMSSE, Theil‚Äôs U  \n","- **Uncertainty-aware:** NLL, CRPS  \n","- **Images/audio:** PSNR, SSIM  \n"],"metadata":{"id":"4oyfJLAPbKVF"}},{"cell_type":"markdown","source":["# üìú Unified Evaluation Atlas: Classification vs Regression (AI/ML/DL)\n","\n","---\n","\n","## üîπ Classification Metrics\n","\n","| Metric            | Formula (simplified)                                      | Intuition                           | Pros                        | Cons                              | When to Use                          |\n","| ----------------- | --------------------------------------------------------- | ----------------------------------- | --------------------------- | --------------------------------- | ------------------------------------ |\n","| **Accuracy**      | $Acc = \\frac{TP+TN}{TP+TN+FP+FN}$                         | Overall correctness                 | Simple, intuitive           | Misleading with imbalance          | Balanced datasets                    |\n","| **Precision**     | $Prec = \\frac{TP}{TP+FP}$                                 | Correctness of positives            | Reduces false alarms        | Ignores false negatives            | Fraud detection, spam filters        |\n","| **Recall (TPR)**  | $Rec = \\frac{TP}{TP+FN}$                                  | Coverage of positives                | Captures completeness       | Ignores false positives            | Medical diagnosis                    |\n","| **F1-Score**      | $F1 = 2 \\cdot \\frac{Prec \\cdot Rec}{Prec+Rec}$            | Harmonic mean of P & R               | Balances precision & recall | Harder to interpret for business   | Imbalanced datasets, NLP, CV         |\n","| **Specificity**   | $Spec = \\frac{TN}{TN+FP}$                                 | Correct rejection of negatives       | Complements recall          | Ignores false negatives            | Screening tests                      |\n","| **ROC-AUC**       | Area under ROC (TPR vs FPR)                               | Threshold-free separability          | Robust to imbalance         | Overestimates with skewed data     | Binary classification, ranking       |\n","| **PR-AUC**        | Area under Precision‚ÄìRecall curve                         | Positive class focus                 | Good for imbalance          | Unstable at low recall             | Rare-event detection                 |\n","| **MCC**           | $\\frac{TP\\cdot TN - FP\\cdot FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$ | Correlation between preds & truth | Works with imbalance        | Complex formula                    | Medicine, bioinformatics             |\n","| **Cohen‚Äôs Kappa** | $\\kappa=\\frac{p_o-p_e}{1-p_e}$                            | Chance-corrected accuracy            | Adjusts for imbalance       | Less common in DL                  | Multi-class imbalance                |\n","| **Top-K Accuracy**| Correct if true label $\\in$ top-K predictions             | Ranking correctness                  | Useful for multi-class      | Not useful for binary tasks        | ImageNet, NLP vocab classification   |\n","| **Log-Loss**      | $-\\frac1n\\sum[y\\log p+(1-y)\\log(1-p)]$                    | Probabilistic confidence             | Good for calibration        | Sensitive to outliers              | Calibration of classifiers           |\n","| **Brier Score**   | $\\frac1n\\sum(p-y)^2$                                      | Probability calibration              | Interpretable               | Not scale-free                     | Risk & reliability models            |\n","| **Jaccard Index** | $\\frac{TP}{TP+FP+FN}$                                     | Overlap measure                      | Good for multi-label        | Ignores true negatives             | Segmentation, multi-label tasks      |\n","\n","---\n","\n","## üîπ Regression Metrics\n","\n","| Metric               | Formula (simplified)                                      | Intuition                        | Pros                             | Cons                                    | When to Use                           |\n","| -------------------- | --------------------------------------------------------- | -------------------------------- | -------------------------------- | --------------------------------------- | ------------------------------------- |\n","| **MAE**              | $\\frac{1}{n}\\sum |y-\\hat{y}|$                             | Avg. absolute error              | Robust to outliers               | Doesn‚Äôt penalize large errors strongly  | General regression, skewed data       |\n","| **MSE**              | $\\frac{1}{n}\\sum (y-\\hat{y})^2$                           | Penalizes large errors           | Smooth gradients, standard loss  | Sensitive to outliers                   | Gaussian noise, stable datasets        |\n","| **RMSE**             | $\\sqrt{\\frac{1}{n}\\sum (y-\\hat{y})^2}$                    | Error in same units as target    | Interpretable                    | Same issues as MSE                      | Reporting model fit                    |\n","| **Median AE**        | $\\text{median}(|y-\\hat{y}|)$                              | Typical (median) error           | Very robust to extreme outliers  | Ignores variance of large errors        | Heavy-tailed noise                     |\n","| **MAPE**             | $\\frac{100}{n}\\sum \\left|\\frac{y-\\hat{y}}{y}\\right|$      | Percent error                    | Scale-free, intuitive            | Undefined if $y=0$                      | Forecasting/business KPIs              |\n","| **sMAPE**            | $\\frac{200}{n}\\sum \\frac{|y-\\hat{y}|}{|y|+|\\hat{y}|}$     | Symmetric % error                | Scale-free, handles symmetry     | Still unstable near 0                   | Time-series forecasting                |\n","| **R¬≤**               | $1 - \\frac{\\sum (y-\\hat{y})^2}{\\sum (y-\\bar{y})^2}$       | Variance explained               | Intuitive fit measure            | Misleading for nonlinear models         | Model fit evaluation                   |\n","| **Adjusted R¬≤**      | $1-(1-R^2)\\frac{n-1}{n-p-1}$                              | Penalized R¬≤                     | Penalizes overfitting            | Only valid for linear models            | Feature set evaluation                 |\n","| **Huber Error**      | Quadratic for small errors, linear for large ones         | Hybrid of L1 & L2                | Robust + smooth optimization     | Requires Œ¥ tuning                       | Outlier-prone regression               |\n","| **RMSLE**            | $\\sqrt{\\frac{1}{n}\\sum(\\log(1+y)-\\log(1+\\hat{y}))^2}$     | Penalizes relative errors        | Handles exponential growth       | Undefined if $y<0$                      | Finance, growth prediction             |\n","| **MASE**             | $\\frac{MAE}{MAE_{\\text{naive}}}$                          | Error relative to naive forecast | Scale-free, interpretable        | Needs baseline                          | Forecasting competitions               |\n","| **CRPS**             | $\\int (F(y)-\\mathbb{1}(t\\le y))^2 dt$                     | Distributional accuracy          | Proper probabilistic metric      | Costly to compute                       | Probabilistic forecasting              |\n","| **PSNR / SSIM**      | $PSNR=10\\log_{10}\\frac{MAX^2}{MSE}$; SSIM = structure fn. | Signal/structure similarity      | Correlates with human perception | Task-specific, non-convex               | Images, audio, generative tasks        |\n","\n","---\n","\n","## ‚úÖ Cross-Family Insights\n","\n","- **Classification** ‚Üí discrete outcomes: metrics come from the **confusion matrix** & **probability calibration**.  \n","- **Regression** ‚Üí continuous outcomes: metrics focus on **error magnitudes, variance explained, and scale-free comparisons**.  \n","\n","**When data is imbalanced:**  \n","- Classification ‚Üí **PR-AUC, F1, MCC**.  \n","- Regression ‚Üí **Median AE, Huber, RMSLE**.  \n","\n","**When uncertainty matters:**  \n","- Classification ‚Üí **Log-Loss, Brier Score**.  \n","- Regression ‚Üí **NLL, CRPS**.  \n","\n","**When interpretability for business matters:**  \n","- Classification ‚Üí **Accuracy, Precision, Recall**.  \n","- Regression ‚Üí **MAE, MAPE, RMSE**.  \n"],"metadata":{"id":"283nwK-pbjrV"}}]}