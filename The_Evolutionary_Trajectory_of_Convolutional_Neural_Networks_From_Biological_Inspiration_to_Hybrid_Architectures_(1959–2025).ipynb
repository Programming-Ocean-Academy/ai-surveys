{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  Chronological Evolution of Convolutional Neural Networks (CNNs)\n",
        "\n",
        "---\n",
        "\n",
        "## **Timeline of Key Papers and Milestones**\n",
        "\n",
        "| Year | Authors | Paper / Contribution | Idea | Contribution | Gap Filled |\n",
        "|------|---------|----------------------|------|--------------|------------|\n",
        "| **1959â€“1968** | Hubel & Wiesel | â€” | Discovered receptive fields in cat visual cortex. | Inspired local connectivity and feature hierarchies. | Provided biological foundation for CNNs. |\n",
        "| **1969** | Kunihiko Fukushima | â€” | Introduced multilayer visual models with shared interconnections. Proposed early form of ReLU activation. | First vision models inspired by cortical hierarchy. | Introduced idea of shared weights and nonlinearity. |\n",
        "| **1980** | Fukushima | *Neocognitron* | First CNN-like architecture with **S-layers (convolutions)** and **C-layers (downsampling)**. | Direct biological inspiration; precursor of CNN pooling. | Showed hierarchical feature extraction, but no backprop training. |\n",
        "| **1987** | Homma, Atlas & Marks | NeurIPS | Applied convolution in time for speech recognition. | Linked CNNs to signal processing concepts. | Established shift-invariance in time signals. |\n",
        "| **1987** | Waibel et al. | *Time-Delay Neural Network (TDNN)* | 1D convolution along time axis for phoneme recognition. | First CNN trained with backpropagation + weight sharing. | Practical application in speech recognition. |\n",
        "| **1988â€“1991** | Zhang et al. | â€” | CNNs for handwritten characters and medical imaging. | Trained kernels with backprop. | Early CNN applications in vision and healthcare. |\n",
        "| **1989** | LeCun et al. | â€” | Applied CNNs with backprop to digit recognition. | Established CNNs as foundational for computer vision. | Paved way for practical CNN adoption. |\n",
        "| **1990** | Yamaguchi et al. | â€” | Introduced **max pooling** with TDNNs. | Improved invariance for speech recognition. | Enhanced robustness to variability. |\n",
        "| **1993** | Weng et al. | *Crescetpron* | Introduced **max pooling** in vision CNNs. | Stronger invariance than Fukushimaâ€™s averaging. | Improved generalization in vision tasks. |\n",
        "| **1995** | LeCun | *LeNet-5* | 7-layer CNN for digit recognition on checks. | Deployed commercially in U.S. banks. | First widespread real-world application of CNNs. |\n",
        "| **2004â€“2006** | Oh, Jung; Chellapilla et al. | â€” | Implemented CNNs on GPUs. | 20â€“60Ã— speedups. | Enabled deeper CNN training. |\n",
        "| **2010â€“2011** | Ciresan et al. (IDSIA) | â€” | Deep CNNs trained with GPUs. | Achieved superhuman accuracy on benchmarks. | Sparked revival of deep CNN research. |\n",
        "| **2012** | Krizhevsky, Sutskever & Hinton | *AlexNet* | 8-layer CNN, ReLU, dropout, GPU training. | Won ImageNet (15.3% vs 26% error). | Catalyst for deep learning boom. |\n",
        "| **2014** | Szegedy et al. | *GoogLeNet (Inception)* | Multi-scale convolutions, 22 layers. | Improved efficiency with inception modules. | Showed depth + width scaling works. |\n",
        "| **2014** | Simonyan & Zisserman | *VGGNet* | Stacked 3Ã—3 conv layers. | Depth matters (16â€“19 layers). | Set new SOTA in vision tasks. |\n",
        "| **2015** | He et al. | *ResNet* | Residual connections. | Solved vanishing gradient, trained >1000 layers. | Opened ultra-deep CNN training. |\n",
        "| **2015** | AtomNet | â€” | CNNs for drug discovery. | Modeled 3D chemical structures. | First major biomedical CNN use. |\n",
        "| **2015** | Face Recognition / Video CNNs | â€” | Applied to face recognition + spatio-temporal tasks. | Surpassed human-level face recognition. | Extended CNNs to dynamic vision. |\n",
        "| **2015** | Mnih et al. | *Deep Q-Network (DQN)* | Combined CNNs with RL for Atari. | Learned directly from pixels. | Merged CNNs with reinforcement learning. |\n",
        "| **2016** | Szegedy et al. | *Inception-v3, Inception-ResNet* | Mixed inception + residuals. | Increased efficiency + depth. | State-of-the-art CNN variants. |\n",
        "| **2017** | Hinton et al. | *Capsule Networks* | Introduced capsules to model pose relationships. | Addressed CNN limitations in spatial hierarchy. | Proposed alternative to pooling invariance. |\n",
        "| **2017** | Vaswani et al. | *Attention is All You Need* | Transformer for NLP. | Began shift away from CNNs. | Outperformed CNNs in sequence tasks. |\n",
        "| **2018** | Tan & Le | *EfficientNet* | Compound scaling (depth, width, resolution). | Efficient SOTA CNN scaling. | Maximized accuracy per FLOP. |\n",
        "| **2020** | Dosovitskiy et al. | *Vision Transformer (ViT)* | Applied self-attention to images. | Replaced convolutions in vision SOTA. | Challenged CNN dominance. |\n",
        "| **2021â€“2025** | Liu et al., ConvNeXt, Swin, hybrids | â€” | CNN + Transformer hybrids. | Retained CNN efficiency + transformer scalability. | Balanced efficiency and performance for edge deployment. |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Summary Verdict**\n",
        "\n",
        "- **1960sâ€“1980s:** Biological inspiration â†’ first CNN-like ideas.  \n",
        "- **1990s:** Trainable CNNs (LeNet) â†’ practical adoption.  \n",
        "- **2000s:** GPU acceleration â†’ deep CNN feasibility.  \n",
        "- **2012â€“2018:** CNNs dominated SOTA in vision (AlexNet, VGG, ResNet, EfficientNet).  \n",
        "- **2020+:** Vision Transformers challenged CNN dominance.  \n",
        "- **2021â€“2025:** CNNs remain crucial for **efficiency, low-data tasks, and real-time/edge AI**, while hybrids with Transformers define the frontier.  \n"
      ],
      "metadata": {
        "id": "JGh6Pt2mJn-e"
      }
    }
  ]
}