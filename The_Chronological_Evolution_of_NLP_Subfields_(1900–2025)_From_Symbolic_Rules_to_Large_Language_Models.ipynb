{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📖 Chronological Evolution of NLP Subfields (1900–2025)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. 🧩 Foundations of Computational Linguistics (1900–1960s)\n",
        "\n",
        "- 1900s–1930s – Mathematical linguistics (Saussure’s structuralism, Zipf’s law on word frequency).  \n",
        "- 1940s – First work on machine translation (Warren Weaver, 1949 memo).  \n",
        "- 1950 – Alan Turing, “Computing Machinery and Intelligence” → Turing Test.  \n",
        "- 1952–1954 – Georgetown-IBM experiment: automatic English → Russian word-for-word MT.  \n",
        "- 1957 – Chomsky’s *Syntactic Structures* introduces transformational grammar.  \n",
        "- 1960s – ELIZA (Weizenbaum, 1966): first chatbot (rule-based).  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. 📚 Rule-Based & Symbolic NLP (1960s–1980s)\n",
        "\n",
        "- 1960s – SYSTRAN: rule-based MT system (used by NASA/EC).  \n",
        "- 1970 – SHRDLU (Winograd): natural language understanding in constrained microworlds.  \n",
        "- 1970s – Knowledge-based systems (frames, semantic networks).  \n",
        "- 1980s – Expert systems & symbolic parsing (ATNs, DCGs).  \n",
        "\n",
        "Limited scalability → motivated shift to statistical methods.  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. 📊 Statistical NLP Era (1980s–1990s)\n",
        "\n",
        "- 1983 – IBM Candide Project: statistical MT using aligned bilingual corpora.  \n",
        "- 1988 – Church & Mercer: Hidden Markov Models for speech recognition.  \n",
        "- 1990s – SMT dominates (Brown et al., IBM Models 1–5).  \n",
        "- 1993 – BLEU precursor metrics introduced.  \n",
        "- 1998 – Maximum Entropy models (Berger, Della Pietra).  \n",
        "\n",
        "---\n",
        "\n",
        "## 4. 🗣️ Speech Recognition & Spoken NLP (1970s–2000s)\n",
        "\n",
        "- 1970s – HARPY (CMU): early speech recognition.  \n",
        "- 1980s – HMMs become standard for ASR.  \n",
        "- 1990s – Dragon Dictate: commercial speech-to-text.  \n",
        "- 2000s – GMM-HMM hybrid models for large vocab speech.  \n",
        "- 2006+ – Deep learning-based ASR (Hinton, 2012): DNN acoustic models.  \n",
        "\n",
        "---\n",
        "\n",
        "## 5. 🌐 Machine Translation (MT)\n",
        "\n",
        "- 1950s–1970s – Rule-based MT (SYSTRAN, Georgetown).  \n",
        "- 1990s – Phrase-based SMT (Koehn, Och).  \n",
        "- 2013 – RCTM (Kalchbrenner & Blunsom): convolution + RNN LM for MT.  \n",
        "- 2014 – Seq2Seq (Sutskever, Vinyals, Le): RNN encoder-decoder.  \n",
        "- 2015 – Bahdanau attention → dynamic context vectors.  \n",
        "- 2017 – Transformer (*Attention is All You Need*, Vaswani et al.).  \n",
        "- 2018 – Ott et al. *Scaling NMT*: large-batch Transformer training.  \n",
        "- 2019–2025 – GPT/ChatGPT-style systems unify translation into universal LLM frameworks.  \n",
        "\n",
        "---\n",
        "\n",
        "## 6. 📖 Language Modeling & Representation Learning\n",
        "\n",
        "- 1980s – N-gram language models.  \n",
        "- 2003 – Bengio et al.: first neural LM.  \n",
        "- 2013 – Word2Vec (Mikolov et al.): distributional word embeddings.  \n",
        "- 2014 – GloVe (Pennington et al.).  \n",
        "- 2018 – BERT (Devlin et al.): bidirectional transformers.  \n",
        "- 2019 – XLNet, RoBERTa → improved pretraining.  \n",
        "- 2020–2025 – GPT-3/4/5, PaLM, LLaMA, Mixtral, DeepSeek models.  \n",
        "\n",
        "---\n",
        "\n",
        "## 7. 🤖 Question Answering & Information Retrieval\n",
        "\n",
        "- 1960s – BASEBALL QA system.  \n",
        "- 1970s–80s – MUC (Message Understanding Conferences).  \n",
        "- 2000s – TREC QA tracks.  \n",
        "- 2012 – IBM Watson (Jeopardy!) → Deep QA.  \n",
        "- 2018 – BERT → SQuAD benchmark breakthroughs.  \n",
        "- 2020s – Open-domain QA with GPT-3/ChatGPT.  \n",
        "\n",
        "---\n",
        "\n",
        "## 8. 📝 Text Classification & Sentiment Analysis\n",
        "\n",
        "- 1990s – Naive Bayes, SVMs for classification.  \n",
        "- 2002 – Pang et al.: sentiment analysis benchmark.  \n",
        "- 2010s – RNNs/CNNs dominate sentiment analysis.  \n",
        "- 2018 – BERT fine-tuning → near-human classification accuracy.  \n",
        "- 2020s – Zero-shot classification with LLMs.  \n",
        "\n",
        "---\n",
        "\n",
        "## 9. ✂️ Summarization\n",
        "\n",
        "- 1950s–70s – Early extractive approaches.  \n",
        "- 2000s – Statistical summarization (LexRank, TextRank).  \n",
        "- 2016 – Seq2Seq + attention for abstractive summarization.  \n",
        "- 2019 – BERTSum, PEGASUS (Google).  \n",
        "- 2020s – ChatGPT-based summarization with controllable styles.  \n",
        "\n",
        "---\n",
        "\n",
        "## 10. 🗣️ Dialogue Systems & Chatbots\n",
        "\n",
        "- 1966 – ELIZA.  \n",
        "- 1972 – PARRY (simulated paranoia patient).  \n",
        "- 2000s – ALICE (AIML-based).  \n",
        "- 2015 – Sequence-to-sequence conversational models.  \n",
        "- 2019–2020 – Meena, BlenderBot.  \n",
        "- 2022–2025 – ChatGPT, Gemini, Claude → general-purpose conversational AI.  \n",
        "\n",
        "---\n",
        "\n",
        "## 11. 🧠 Semantics & Pragmatics\n",
        "\n",
        "- 1970s – Montague grammar.  \n",
        "- 1990s – WordNet lexical database.  \n",
        "- 2000s – Latent Semantic Analysis (LSA), Latent Dirichlet Allocation (LDA).  \n",
        "- 2019 – Sentence-BERT: semantic embeddings.  \n",
        "- 2020s – Embedding-based evaluation (BERTScore, COMET).  \n",
        "\n",
        "---\n",
        "\n",
        "## 12. 📑 Evaluation Metrics in NLP\n",
        "\n",
        "- 1993 – BLEU introduced.  \n",
        "- 2000s – ROUGE (summarization).  \n",
        "- 2010s – METEOR, TER, ChrF.  \n",
        "- 2019–2020s – BERTScore, BLEURT, COMET, MoverScore.  \n",
        "- 2025 – Hybrid metrics combining automatic + human preference models.  \n",
        "\n",
        "---\n",
        "\n",
        "## 13. ⚡ Recent Cutting-Edge Subfields (2020–2025)\n",
        "\n",
        "- Multilingual LLMs (mBERT, XLM-R).  \n",
        "- Low-resource NLP with transfer + few-shot learning.  \n",
        "- Code LLMs (Codex, AlphaCode, StarCoder).  \n",
        "- Multimodal NLP (CLIP, Flamingo, GPT-4V, Gemini).  \n",
        "- Responsible NLP → bias, fairness, toxicity mitigation.  \n",
        "- Efficiency research → distillation, quantization, retrieval-augmented LMs (RAG).  \n",
        "\n",
        "---\n",
        "\n",
        "## 🎓 Conclusion\n",
        "From rule-based linguistics in the 1950s to transformer-based LLMs in the 2020s, NLP has evolved across distinct subfields: MT, LM, QA, IR, summarization, dialogue, semantics, evaluation, and multimodality. Each milestone reflects a shift in paradigm:\n",
        "\n",
        "**Symbolic → Statistical → Neural RNNs → Attention → Transformers → LLMs.**"
      ],
      "metadata": {
        "id": "mjco0MKmCOHE"
      }
    }
  ]
}