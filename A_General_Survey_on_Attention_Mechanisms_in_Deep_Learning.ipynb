{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Paper Summary — “A General Survey on Attention Mechanisms in Deep Learning”  \n",
        "**Authors:** Gianni Brauwers & Flavius Frasincar (Erasmus University Rotterdam)\n",
        "\n",
        "# https://arxiv.org/abs/2203.14263\n",
        "\n",
        "---\n",
        "\n",
        "### **Abstract**\n",
        "\n",
        "This paper presents a comprehensive cross-domain survey of attention mechanisms in deep learning. It introduces a unified framework and notation for understanding how attention operates, offers a detailed taxonomy that classifies mechanisms based on feature-, query-, and general-related properties, and reviews methods for evaluating attention models. The paper synthesizes prior research across NLP, vision, and other domains to provide a structured overview and identify future research opportunities in model interpretability and architecture design.\n",
        "\n",
        "---\n",
        "\n",
        "### **Problems**\n",
        "\n",
        "1. **Fragmented Literature:** Prior surveys focus narrowly on domain-specific uses (e.g., NLP or vision), lacking an integrative framework.  \n",
        "2. **Taxonomic Gaps:** Existing classifications do not systematically distinguish mechanisms (e.g., co-attention vs. hierarchical attention).  \n",
        "3. **Technical Incompleteness:** Earlier works often omit mathematical details or intuitive explanations.  \n",
        "4. **Evaluation Inconsistency:** No common set of evaluation metrics or structural characterization methods for attention models.\n",
        "\n",
        "---\n",
        "\n",
        "### **Proposed Solutions**\n",
        "\n",
        "1. **Unified Framework:**  \n",
        "   Establishes a general attention model divided into feature, query, attention, and output submodules—expressed with consistent notation.\n",
        "\n",
        "   $$\n",
        "   \\text{Attention}(Q, K, V) = \\text{softmax}\\left( \\frac{f(Q, K)}{\\sqrt{d_k}} \\right) V\n",
        "   $$\n",
        "\n",
        "   where \\( Q, K, V \\) denote the query, key, and value matrices, respectively, and \\( f(Q, K) \\) represents a scoring function (e.g., dot-product or additive).\n",
        "\n",
        "2. **Comprehensive Taxonomy:**  \n",
        "   Organizes attention mechanisms into three major categories:\n",
        "   * **Feature-related:** multiplicity (co-/rotatory attention), levels (hierarchical/attention-via-attention), representations (multi-representational attention).  \n",
        "   * **Query-related:** query types (self-attention, specialized queries), and multiplicity (multi-head, multi-hop, capsule-based).  \n",
        "   * **General mechanisms:** scoring, alignment, and dimensionality (multi-dimensional vs. scalar attention).\n",
        "\n",
        "3. **Cross-Domain Synthesis:**  \n",
        "   Demonstrates how the same mathematical core generalizes across text, vision, audio, graphs, and time series.\n",
        "\n",
        "4. **Evaluation Guidelines:**  \n",
        "   Reviews performance measures and interpretability criteria for comparing attention structures.\n",
        "\n",
        "---\n",
        "\n",
        "### **Purpose**\n",
        "\n",
        "To provide a domain-agnostic understanding of attention mechanisms by:\n",
        "* Clarifying their mathematical underpinnings.  \n",
        "* Establishing a structural taxonomy applicable to multiple data modalities.  \n",
        "* Bridging conceptual and practical gaps in prior surveys to guide new model design and research directions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Methodology**\n",
        "\n",
        "* **Analytical Framework:** Builds upon Bahdanau et al. (2015) and Vaswani et al. (2017) to generalize attention into a modular system.  \n",
        "* **Comparative Synthesis:** Reviews and categorizes mechanisms by functionality—e.g., coarse vs. fine-grained co-attention, global vs. local alignment.  \n",
        "* **Unified Notation:** Uses consistent mathematical symbols (for queries, keys, values, and context vectors) to express all attention forms.  \n",
        "* **Cross-Domain Mapping:** Demonstrates applicability in NLP (translation, sentiment), CV (captioning, VQA), speech, graphs, and recommendation systems.\n",
        "\n",
        "---\n",
        "\n",
        "### **Results**\n",
        "\n",
        "* **General Model Established:**  \n",
        "  Formalizes how attention scores and weights are computed through scoring, alignment, and context aggregation:\n",
        "  $$\n",
        "  e_{ij} = f(q_i, k_j), \\quad\n",
        "  \\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_j \\exp(e_{ij})}, \\quad\n",
        "  c_i = \\sum_j \\alpha_{ij} v_j\n",
        "  $$\n",
        "* **Taxonomy Created:**  \n",
        "  The paper’s Figure 3 introduces a hierarchical classification that has since influenced follow-up studies.  \n",
        "* **Comparative Analysis:**  \n",
        "  Demonstrates how different score functions (additive, multiplicative, scaled, general) and alignment schemes (soft, hard, local, reinforced) affect interpretability and computational efficiency.  \n",
        "* **Domain Extensions:**  \n",
        "  Confirms that the general framework successfully accommodates complex variants such as multi-head, hierarchical, and co-attention used in Transformers and other architectures.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusions**\n",
        "\n",
        "The survey establishes attention as a universal mechanism for focusing computational resources and improving interpretability across deep learning domains. It unifies previously fragmented concepts under a single theoretical model, offering both practical and conceptual clarity. The authors emphasize that future work should:\n",
        "* Develop standardized evaluation metrics for attention quality.  \n",
        "* Explore hybrid and multi-modal attention integrations.  \n",
        "* Investigate interpretability and fairness aspects of attention-based models.\n",
        "\n",
        "**In essence**, the paper transforms attention from a model-specific innovation into a generalized, mathematically coherent paradigm spanning all areas of modern AI.\n"
      ],
      "metadata": {
        "id": "gLu0yFUyerHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mathematical and Statistical Content Summary**\n",
        "\n",
        "*(Based on “A General Survey on Attention Mechanisms in Deep Learning,” Brauwers & Frasincar, 2022)*\n",
        "\n",
        "---\n",
        "\n",
        "### **1. General Attention Framework**\n",
        "\n",
        "The paper formalizes **attention** as a mathematical mechanism that computes a *weighted average* of feature vectors, where the weights represent the model’s focus on different parts of the input.\n",
        "\n",
        "#### **Core Notation**\n",
        "\n",
        "| Symbol | Meaning |\n",
        "|:-------|:---------|\n",
        "| \\( X \\in \\mathbb{R}^{d_x \\times n_x} \\) | Input matrix (e.g., words, pixels, etc.) |\n",
        "| \\( F = [f_1, \\dots, f_{n_f}] \\in \\mathbb{R}^{d_f \\times n_f} \\) | Feature vectors extracted from input |\n",
        "| \\( q \\in \\mathbb{R}^{d_q} \\) | Query vector – represents the current question or context |\n",
        "| \\( K = [k_1, \\dots, k_{n_f}] \\in \\mathbb{R}^{d_k \\times n_f} \\) | Key vectors – represent the “addresses” of features |\n",
        "| \\( V = [v_1, \\dots, v_{n_f}] \\in \\mathbb{R}^{d_v \\times n_f} \\) | Value vectors – represent the “content” to extract |\n",
        "| \\( a = [a_1, \\dots, a_{n_f}] \\) | Attention weights |\n",
        "| \\( c \\in \\mathbb{R}^{d_v} \\) | Context vector – the final weighted output |\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Linear Transformations of Features**\n",
        "\n",
        "The feature matrix \\( F \\) is transformed into keys and values using learnable matrices:\n",
        "\n",
        "$$\n",
        "K = W_K F, \\quad V = W_V F\n",
        "$$\n",
        "\n",
        "where \\( W_K \\in \\mathbb{R}^{d_k \\times d_f} \\) and \\( W_V \\in \\mathbb{R}^{d_v \\times d_f} \\) are trainable weight matrices.\n",
        "\n",
        "**Purpose:** To map features into different subspaces suitable for computing attention scores and extracting context.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Attention Scoring Function**\n",
        "\n",
        "The *score function* measures how relevant each key \\( k_l \\) is to the query \\( q \\):\n",
        "\n",
        "$$\n",
        "e_l = \\text{score}(q, k_l)\n",
        "$$\n",
        "\n",
        "This scalar score \\( e_l \\) is then normalized into a probability-like weight \\( a_l \\).\n",
        "\n",
        "#### **Common Score Functions**\n",
        "\n",
        "| Type | Equation | Intuition |\n",
        "|:------|:----------|:-----------|\n",
        "| **Additive (Bahdanau)** | \\( e_l = w^\\top \\text{act}(W_1 q + W_2 k_l + b) \\) | Combines query and key via learned linear layers; nonlinear activation adds flexibility. |\n",
        "| **Multiplicative (Luong)** | \\( e_l = q^\\top k_l \\) | Measures similarity using a dot product; fast but less flexible. |\n",
        "| **Scaled Dot Product (Vaswani)** | \\( e_l = \\frac{q^\\top k_l}{\\sqrt{d_k}} \\) | Reduces large values in high dimensions to stabilize gradients. |\n",
        "| **General / Biased / Activated** | \\( e_l = k_l^\\top W q + b \\) or \\( \\text{act}(k_l^\\top W q + b) \\) | Adds learnable weights and bias; can include nonlinearity. |\n",
        "| **Similarity-based** | \\( e_l = \\text{sim}(q, k_l) \\) | Uses distance or cosine similarity. |\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Alignment Function (Normalization)**\n",
        "\n",
        "Once scores \\( e = [e_1, \\dots, e_{n_f}] \\) are computed, they are normalized into attention weights:\n",
        "\n",
        "$$\n",
        "a_l = \\frac{\\exp(e_l)}{\\sum_{j=1}^{n_f} \\exp(e_j)} \\quad \\text{(Softmax)}\n",
        "$$\n",
        "\n",
        "This ensures all weights are positive and sum to 1 — producing a *probability distribution of attention* across inputs.\n",
        "\n",
        "**Alternative alignments:**\n",
        "\n",
        "* **Hard attention:** samples one vector based on probabilities (non-differentiable, trained via reinforcement learning).  \n",
        "* **Local attention:** applies softmax within a limited window around a predicted position \\( p \\).  \n",
        "* **Reinforced alignment:** selects subsets of vectors using a policy network.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Context Vector Computation**\n",
        "\n",
        "The **output of attention** is a weighted average of value vectors:\n",
        "\n",
        "$$\n",
        "c = \\sum_{l=1}^{n_f} a_l v_l\n",
        "$$\n",
        "\n",
        "* This operation fuses information from multiple features according to their learned importance.  \n",
        "* It is equivalent to computing an **expectation** over features under the distribution \\( a_l \\).\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Output Prediction**\n",
        "\n",
        "The context vector is transformed into final predictions:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\text{softmax}(W_c c + b_c)\n",
        "$$\n",
        "\n",
        "* Here \\( W_c \\) and \\( b_c \\) are trainable parameters.  \n",
        "* The softmax converts the output into probabilities over classes (for classification tasks).\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Multi-dimensional Attention**\n",
        "\n",
        "Extends scalar attention weights \\( a_l \\) to vector-valued weights \\( a_l \\in \\mathbb{R}^{d_v} \\):\n",
        "\n",
        "$$\n",
        "c = \\sum_{l=1}^{n_f} a_l \\circ v_l\n",
        "$$\n",
        "\n",
        "where \\( \\circ \\) denotes element-wise multiplication.\n",
        "\n",
        "* Each feature dimension gets its own weight → enables fine-grained control within each vector component.\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Hierarchical and Multi-level Attention**\n",
        "\n",
        "In **hierarchical models**, attention is applied recursively:\n",
        "\n",
        "1. Compute attention at word-level → get sentence representations.  \n",
        "2. Compute attention at sentence-level → get document representation.\n",
        "\n",
        "If \\( c^{(s)} \\) are sentence vectors:\n",
        "\n",
        "$$\n",
        "c^{(D)} = \\sum_{s} a_s c^{(s)}\n",
        "$$\n",
        "\n",
        "* Each level reuses the same weighted-average principle.\n",
        "\n",
        "---\n",
        "\n",
        "### **9. Co-Attention and Multi-Input Extensions**\n",
        "\n",
        "For models with two inputs (e.g., question & image), co-attention computes mutual relevance.\n",
        "\n",
        "* **Alternating co-attention:** use one input’s context as the query for the other.  \n",
        "* **Parallel co-attention:** construct an *affinity matrix* \\( A \\) that measures pairwise similarity:\n",
        "\n",
        "$$\n",
        "A = \\text{act}(K^{(1)T} W_A K^{(2)})\n",
        "$$\n",
        "\n",
        "* \\( A_{ij} \\) reflects similarity between features of two modalities.  \n",
        "* Aggregating over \\( A \\) yields cross-modal attention scores.\n",
        "\n",
        "---\n",
        "\n",
        "### **10. Statistical Interpretation**\n",
        "\n",
        "The attention mechanism can be viewed as a **probability-weighted estimator**:\n",
        "\n",
        "$$\n",
        "c = \\mathbb{E}_{a}[v]\n",
        "$$\n",
        "\n",
        "where \\( a \\) represents an attention distribution over input features.\n",
        "\n",
        "Thus, attention serves as a **data-driven importance sampling** process that adaptively reweights observations.\n",
        "\n",
        "---\n",
        "\n",
        "### **11. Multi-head and Self-Attention**\n",
        "\n",
        "For **multi-head attention**:\n",
        "\n",
        "$$\n",
        "\\text{MultiHead}(Q,K,V) = [\\text{head}_1, \\dots, \\text{head}_h] W^O\n",
        "$$\n",
        "\n",
        "with each head computing attention on different projections:\n",
        "\n",
        "$$\n",
        "\\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)\n",
        "$$\n",
        "\n",
        "For **self-attention**, the query, key, and value all come from the same feature matrix:\n",
        "\n",
        "$$\n",
        "Q = W_Q F, \\quad K = W_K F, \\quad V = W_V F\n",
        "$$\n",
        "\n",
        "* This allows modeling of dependencies between all elements in the same sequence or image.  \n",
        "* Mathematically, it builds a *relation matrix* capturing pairwise interactions among features.\n",
        "\n",
        "---\n",
        "\n",
        "### **12. Statistical Learning Aspects**\n",
        "\n",
        "Although the paper does not conduct experiments, it relies on standard **supervised learning** principles:\n",
        "\n",
        "* All weight matrices \\( W_K, W_V, W_Q, W_c \\) are optimized via **gradient descent** and **backpropagation**.  \n",
        "* Softmax and normalization ensure numerical stability during optimization.  \n",
        "* Scaled dot-product reduces variance of gradients (statistical stabilization).\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "\n",
        "| **Concept** | **Mathematical Role** | **Intuitive Role in the Paper** |\n",
        "|:-------------|:----------------------|:--------------------------------|\n",
        "| Linear Transformations | \\( K = W_K F, \\; V = W_V F \\) | Learn how to represent information as address (K) and content (V). |\n",
        "| Score Function | \\( e_l = \\text{score}(q, k_l) \\) | Compute relevance between query and each feature. |\n",
        "| Softmax Alignment | \\( a_l = \\frac{\\exp(e_l)}{\\sum_j \\exp(e_j)} \\) | Convert scores into a probability-like focus. |\n",
        "| Context Vector | \\( c = \\sum_l a_l v_l \\) | Weighted combination of features = attention output. |\n",
        "| Multi-head Extension | Parallel sets of attention computations | Capture multiple relational patterns simultaneously. |\n",
        "| Co-/Hierarchical Attention | Nested or cross-modal weighting | Combine structured or multimodal inputs adaptively. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Final Insight**\n",
        "\n",
        "The mathematical structure shows that **attention is a generalized weighting mechanism** built upon linear algebra and probability normalization.  \n",
        "Every variant—whether additive, dot-product, or hierarchical—is an adaptation of the same core concept:\n",
        "\n",
        "$$\n",
        "\\text{Weighted aggregation of information based on learned relevance.}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "NT6tzs0ZgJUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| # | **Research Problem / Gap Identified** | **How It Limits Prior Work** | **Proposed Solution in This Paper** |\n",
        "|---|--------------------------------------|--------------------------------|------------------------------------|\n",
        "| **1** | Fragmented, domain-specific surveys on attention mechanisms | Existing reviews focus narrowly on single domains (e.g., NLP, vision, or graphs), preventing a unified understanding of attention across tasks and data modalities. | Develops a cross-domain survey presenting attention mechanisms in a generalized mathematical and conceptual framework applicable to multiple domains. |\n",
        "| **2** | Lack of a consistent mathematical framework for attention | Previous works describe attention intuitively or qualitatively, without a unified formalism, making comparisons difficult. | Introduces a general attention model composed of feature, query, attention, and output submodules with uniform notation and explicit mathematical definitions. |\n",
        "| **3** | Absence of a structured taxonomy distinguishing attention variants | Earlier taxonomies fail to distinguish mechanisms such as co-attention, hierarchical attention, and self-attention systematically, leading to conceptual overlap. | Proposes a comprehensive taxonomy that categorizes attention mechanisms into feature-related, query-related, and general classes with clear subtypes and hierarchy. |\n",
        "| **4** | Insufficient integration of technical and intuitive explanations | Many surveys emphasize either theory (equations) or intuition (descriptions), causing a gap between understanding and implementation. | Combines technical derivations (e.g., scoring, alignment, and weighting) with intuitive examples from NLP, vision, and multimodal learning for accessible comprehension. |\n",
        "| **5** | Inconsistent evaluation and interpretability frameworks for attention models | Lack of standard metrics or methods hinders comparison of different attention mechanisms’ performance and interpretability. | Reviews and formalizes evaluation measures for attention quality, interpretability, and model performance; suggests structural analysis using the proposed taxonomy. |\n",
        "| **6** | Limited understanding of cross-modal and multi-level attention | Prior research rarely connects how attention operates across multiple modalities (e.g., vision + text) or hierarchical levels (e.g., word, sentence, document). | Illustrates cross-modal extensions (co-attention, rotatory attention) and multi-level architectures (hierarchical and attention-via-attention) within the same framework. |\n",
        "| **7** | Lack of theoretical unification between classic RNN-based attention and Transformer-based self-attention | Fragmented explanations of how modern self-attention evolved from earlier sequence models impede theoretical continuity. | Unifies both paradigms under one formal model showing that attention is sufficient as a standalone computation, exemplified by the Transformer architecture. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary Insight**\n",
        "\n",
        "This paper closes the conceptual and methodological gaps in prior literature by **formalizing attention as a general, domain-agnostic mechanism**, integrating **mathematical rigor**, **structural taxonomy**, and **evaluation consistency**—thereby transforming attention from a collection of heuristic techniques into a **unified theoretical framework in deep learning**.\n"
      ],
      "metadata": {
        "id": "t-I1tYEfe6qX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TABLE 3 — Attention Models Analyzed Based on the Proposed Taxonomy**\n",
        "\n",
        "*A plus sign (+) between two mechanisms indicates that both techniques were combined in the same model, while a comma (,) indicates that both mechanisms were tested in the same paper, but not necessarily as a combination in the same model.*\n",
        "\n",
        "| **Model / Paper** | **Feature-Related: Multiplicity** | **Feature-Related: Levels** | **Feature-Related: Representations** | **General: Scoring** | **General: Alignment** | **General: Dimensionality** | **Query-Related: Type** | **Query-Related: Multiplicity** |\n",
        "|--------------------|----------------------------------|-----------------------------|-------------------------------------|-----------------------|-------------------------|-----------------------------|--------------------------|----------------------------------|\n",
        "| Bahdanau et al. [3] | Singular | Single-Level | Single-Representational | Additive | Global | Single-Dimensional | Basic | Singular |\n",
        "| Luong et al. [4] | Singular | Single-Level | Single-Representational | Multiplicative, Location | Global, Local | Single-Dimensional | Basic | Singular |\n",
        "| Xu et al. [8] | Singular | Single-Level | Single-Representational | Additive | Soft, Hard | Single-Dimensional | Basic | Singular |\n",
        "| Lu et al. [32] | Parallel Co-attention | Hierarchical | Single-Representational | Additive | Soft, Global | Single-Dimensional | Specialized | Singular |\n",
        "| Yang et al. [5] | Singular | Hierarchical | Single-Representational | Additive | Global | Single-Dimensional | Self-Attentive | Singular |\n",
        "| Li et al. [47] | Singular | Hierarchical | Single-Representational | Additive | Global | Single-Dimensional | Self-Attentive | Singular |\n",
        "| Vaswani et al. [13] | Singular | Single-Level | Single-Representational | Scaled-Multiplicative | Global | Single-Dimensional | Self-Attentive + Basic | Multi-Hop |\n",
        "| Wallaart and Frasincar [43] | Rotatory | Single-Level | Single-Representational | Activated General | Additive | Global | Specialized | Singular |\n",
        "| Kiela et al. [50] | Singular | Single-Level | Multi-Representational | Additive | Global | Single-Dimensional | Self-Attentive | Singular |\n",
        "| Shen et al. [64] | Singular | Single-Level | Single-Representational | Additive | Global | Multi-Dimensional | Self-Attentive | Singular |\n",
        "| Zhang et al. [74] | Singular | Single-Level | Single-Representational | Scaled-Multiplicative | Global | Single-Dimensional | Self-Attentive + Specialized | Singular |\n",
        "| Li et al. [105] | Parallel Co-attention | Single-Level | Single-Representational | Multiplicative | Global | Single-Dimensional | Self-Attentive + Specialized | Multi-Hop |\n",
        "| Yu et al. [106] | Parallel Co-attention | Single-Level | Single-Representational | Additive | Reinforced | Single-Dimensional | Self-Attentive | Singular |\n",
        "| Wang et al. [62] | Parallel Co-attention | Single-Level | Single-Representational | Additive | Global | Single-Dimensional | Self-Attentive | Singular |\n",
        "| Oktay et al. [67] | Singular | Single-Level | Single-Representational | Additive | Global | Multi-Dimensional | Self-Attentive + Specialized | Singular |\n",
        "| Winata et al. [52] | Singular | Single-Level | Multi-Representational | Additive | Global | Single-Dimensional | Self-Attentive | Multi-Head |\n",
        "| Wang et al. [89] | Singular | Single-Level | Single-Representational | Additive | Global | Single-Dimensional | Self-Attentive | Capsule-Based |\n"
      ],
      "metadata": {
        "id": "viW1z7BBf8Vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Academic Interpretation of Table 3**\n",
        "\n",
        "---\n",
        "\n",
        "### **Purpose of the Table**\n",
        "\n",
        "Table 3 is designed to **validate the proposed taxonomy of attention mechanisms** by mapping well-known attention models from the literature onto the framework introduced by Brauwers & Frasincar (2022).  \n",
        "It systematically classifies each foundational paper—such as **Bahdanau (2015), Luong (2015), Xu (2015), Vaswani (2017)**—along structural and functional dimensions.  \n",
        "This mapping demonstrates that the taxonomy is not merely theoretical but can be **empirically applied** to describe and compare diverse architectures across domains (NLP, vision, multimodal learning).\n",
        "\n",
        "---\n",
        "\n",
        "### **Axes and Aspects Used to Construct the Table**\n",
        "\n",
        "| **Aspect** | **What It Means** | **Why It Matters** |\n",
        "|:------------|:------------------|:-------------------|\n",
        "| **Multiplicity** | Whether the model uses one attention mechanism (Singular) or multiple combined ones (e.g., Parallel, Co-attention, Rotatory). | Reveals if the model’s attention operates on a single source of features or integrates multiple sources/modalities (e.g., image + text). |\n",
        "| **Feature-Related** | Specifies the structure of the input features: Single-Level (flat), Hierarchical (multi-level), Single-Representational (one embedding), or Multi-Representational (multiple embeddings). | Identifies whether the model attends to one representational layer or several hierarchical ones (e.g., words → sentences). |\n",
        "| **General** | Indicates the mathematical design of the attention core: scoring, alignment, and dimensionality. | Demonstrates which scoring or weighting method (additive, multiplicative, scaled) and which alignment (global, hard, local) are used, showing how relevance is computed. |\n",
        "| **Dimensionality** | Whether the attention weights are scalars (Single-Dimensional) or vectors (Multi-Dimensional). | Reflects the granularity of focus—entire feature vectors versus individual elements within them. |\n",
        "| **Type (Query-Related)** | Describes how the query is defined—Basic (fixed query), Self-Attentive (query = feature itself), Specialized (cross-modal), etc. | Differentiates models that use external queries (e.g., decoder states) from those that use self-attention or task-specific mechanisms. |\n",
        "| **Query Multiplicity** | Whether the model employs one query (Singular), several queries (Multi-Head), or iterative queries (Multi-Hop). | Distinguishes classical attention from modern multi-head/self-attention systems like the Transformer. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Interpretive Reading of the Table**\n",
        "\n",
        "Each row corresponds to a **distinct attention architecture**, classified according to the proposed taxonomy.\n",
        "\n",
        "| **Model** | **Highlights from the Table** | **Interpretation** |\n",
        "|:-----------|:------------------------------|:-------------------|\n",
        "| **Bahdanau et al. (2015)** | Singular / Single-Level / Additive / Global / Basic / Singular | Prototype additive attention for RNNs — the foundational “encoder–decoder” model integrating alignment and translation. |\n",
        "| **Luong et al. (2015)** | Singular / Single-Level / Multiplicative / Global / Basic / Singular | Introduces dot-product attention for computational efficiency; conceptually similar to Bahdanau but with different scoring. |\n",
        "| **Xu et al. (2015)** | Singular / Single-Representational / Additive / Soft, Hard / Basic / Singular | The “Show, Attend and Tell” model — extends attention to visual domains and introduces both deterministic and stochastic alignments. |\n",
        "| **Vaswani et al. (2017)** | Singular / Single-Representational / Scaled / Global / Self-Attentive / Multi-Head + Multi-Hop | The Transformer — introduces multi-head self-attention as a standalone mechanism, generalizing attention to all input positions simultaneously. |\n",
        "| **Wallaart & Frasincar (2021)** | Rotatory / Single-Level / Single-Representational / Activated / Global / Specialized / Multi-Hop | A sentiment analysis model using rotating attention queries; exemplifies specialization within the unified taxonomy. |\n",
        "\n",
        "Through this mapping, the table captures **how successive models evolved**—from RNN-based additive attention to multi-head self-attention—while remaining describable under the same mathematical structure.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why These Aspects Were Chosen**\n",
        "\n",
        "1. **Taxonomic Completeness:**  \n",
        "   The paper’s taxonomy divides attention mechanisms into three orthogonal groups—**feature-related**, **general**, and **query-related**.  \n",
        "   Table 3 operationalizes these categories with empirical evidence.\n",
        "\n",
        "2. **Cross-Domain Applicability:**  \n",
        "   By combining **structural descriptors** (e.g., hierarchy, multiplicity) and **mathematical attributes** (e.g., scoring, alignment), the taxonomy becomes **domain-agnostic**, applicable across text, vision, graphs, and multimodal settings.\n",
        "\n",
        "3. **Comparative Clarity:**  \n",
        "   Earlier surveys lacked a consistent comparative framework.  \n",
        "   This table standardizes the analysis, revealing conceptual continuities (e.g., **Bahdanau → Luong → Vaswani**) across architectures.\n",
        "\n",
        "4. **Framework Validation:**  \n",
        "   Populating the taxonomy with canonical models empirically validates that the framework can **classify virtually all existing attention mechanisms** under one notation and conceptual structure.\n",
        "\n",
        "---\n",
        "\n",
        "### **In Summary**\n",
        "\n",
        "Table 3 serves as a **taxonomy validation matrix**.  \n",
        "It classifies major attention architectures across **seven analytical dimensions**—Multiplicity, Feature Level, Representation Type, Scoring, Alignment, Dimensionality, and Query Structure.\n",
        "\n",
        "By synthesizing **architectural design** and **functional operation**, it demonstrates that all known attention mechanisms—from early additive RNN models to modern Transformer-based systems—can be expressed within a **single, mathematically unified framework** proposed by *A General Survey on Attention Mechanisms in Deep Learning*.\n"
      ],
      "metadata": {
        "id": "5tTkMEe2hW09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparative Analysis of Attention Types in Table 3**\n",
        "### *(Based on “A General Survey on Attention Mechanisms in Deep Learning,” Brauwers & Frasincar, 2022)*\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Feature-Related Mechanisms**\n",
        "\n",
        "| **Type** | **Definition** | **Structural Role** | **Example Models** | **Distinctive Insight** |\n",
        "|:----------|:---------------|:--------------------|:--------------------|:--------------------------|\n",
        "| **Singular Attention** | Operates on a *single source* of features (e.g., encoder hidden states). | Focuses on one modality or feature sequence. | Bahdanau (2015), Luong (2015) | The simplest and foundational form—aligns one encoder output set to one decoder query. |\n",
        "| **Parallel Attention** | Runs multiple attention modules *independently* and aggregates their outputs (e.g., summation or concatenation). | Expands representational coverage without dependency among branches. | Li et al. (2018) | Functionally analogous to multi-head attention but at the module level rather than projection level. |\n",
        "| **Co-Attention** | Computes *joint attention* between two modalities (e.g., image ↔ text). | Both modalities act as queries and contexts for each other. | Lu et al. (2016); Yu et al. (2017) | Enables *mutual relevance learning* — the foundation of visual question answering (VQA). |\n",
        "| **Rotatory Attention** | Alternates query–context roles cyclically between components (e.g., Q → A → Q). | Sequential bidirectional focus between dependent inputs. | Wallart & Frasincar (2021) | Models *iterative reasoning* or dialogue exchange symmetry. |\n",
        "| **Hierarchical Attention** | Applies attention recursively (word → sentence → document). | Builds representations at multiple abstraction levels. | Yang et al. (2016) | Captures *compositional hierarchy* and long-range dependencies across textual structures. |\n",
        "| **Multi-Representational Attention** | Operates across different feature encoders (e.g., CNN + RNN). | Fuses heterogeneous embeddings for richer semantics. | Oktay et al. (2018) | Extends attention beyond homogeneous sequences to multi-source input representations. |\n",
        "\n",
        "**Insight:**  \n",
        "Prior reviews grouped *hierarchical* and *co-attention* under “multi-level.”  \n",
        "Brauwers & Frasincar (2022) clarify that hierarchy pertains to *intra-modal* structure, while co-attention refers to *inter-modal* coupling—resolving conceptual ambiguity.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. General Mechanisms (Mathematical Core)**\n",
        "\n",
        "| **Dimension** | **Variants** | **Mathematical Role** | **Interpretation / Importance** |\n",
        "|:---------------|:-------------|:----------------------|:--------------------------------|\n",
        "| **Scoring Function** | Additive (Bahdanau), Multiplicative (Luong), Scaled (Vaswani), Activated (Wallart & Frasincar) | Computes similarity: \\( e_l = \\text{score}(q, k_l) \\). | Determines expressivity–efficiency trade-off: additive (nonlinear, expressive), multiplicative (fast), scaled (stable), activated (nonlinear sharpening). |\n",
        "| **Alignment Function** | Global (Soft), Hard (Stochastic), Local (Windowed), Reinforced (Policy-based) | Normalizes scores into probabilities: \\( a_l = \\frac{\\exp(e_l)}{\\sum_j \\exp(e_j)} \\). | Controls focus scope—global covers all keys; hard/local restricts; reinforced uses policy gradients for discrete sampling. |\n",
        "| **Dimensionality** | Single-Dimensional vs. Multi-Dimensional | Defines scalar vs. vector weights \\( a_l \\). | Scalar weights attend to whole vectors; vector weights enable fine-grained, per-dimension attention. |\n",
        "\n",
        "**Insight:**  \n",
        "The “general” axis abstracts the mathematical machinery independent of data modality—linking all attention forms through a shared probabilistic weighting framework.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Query-Related Mechanisms**\n",
        "\n",
        "| **Type** | **Definition** | **Purpose / Query Source** | **Representative Models** | **Why Distinct** |\n",
        "|:-----------|:----------------|:----------------------------|:----------------------------|:------------------|\n",
        "| **Basic Query** | External or fixed query (e.g., decoder hidden state). | Classical encoder–decoder setting. | Bahdanau (2015), Luong (2015) | Provides the first explicit mechanism defining “what to focus on.” |\n",
        "| **Self-Attentive Query** | Query, key, and value all originate from same feature set. | Captures intra-sequence dependencies. | Vaswani (2017), Yang (2016) | Enables parallel and global relational modeling across inputs. |\n",
        "| **Specialized Query** | Domain- or task-specific query type. | Tailored to specific inputs (e.g., image region, graph node). | Lu et al. (2016); Wallart & Frasincar (2021) | Generalizes query construction beyond linguistic sequences. |\n",
        "| **Multiplicity of Queries** | **Singular**, **Multi-Head**, **Multi-Hop**, **Capsule-Based** | Defines number and iteration of queries. | Vaswani (2017): Multi-Head; Li et al. (2018): Multi-Hop; Wang et al. (2019): Capsule | Expands model capacity for diverse or sequential attention reasoning. |\n",
        "\n",
        "**Key Clarification:**  \n",
        "Older taxonomies merged *multi-head*, *multi-hop*, and *self-attention* under one umbrella.  \n",
        "Brauwers & Frasincar separate them by **query origin** (self vs. external) and **query multiplicity** (parallel vs. sequential vs. hierarchical).\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Comparative Summary Across Table 3 Models**\n",
        "\n",
        "| **Model** | **Feature Focus** | **General Mechanism** | **Query Behavior** | **Interpretation** |\n",
        "|:-----------|:------------------|:-----------------------|:--------------------|:--------------------|\n",
        "| **Bahdanau (2015)** | Singular / Single-Level | Additive + Global | Basic / Singular | Introduced soft additive attention for machine translation; first differentiable alignment mechanism. |\n",
        "| **Luong (2015)** | Singular / Single-Level | Multiplicative + Global | Basic / Singular | Computationally simpler; uses dot-product for faster similarity estimation. |\n",
        "| **Xu et al. (2015)** | Singular / Single-Representational | Additive + Soft, Hard | Basic / Singular | Pioneered visual attention; integrates deterministic and stochastic alignment. |\n",
        "| **Yang (2016)** | Hierarchical / Single-Representational | Additive + Global | Self-Attentive / Singular | Established hierarchical word–sentence document-level modeling (HAN). |\n",
        "| **Vaswani (2017)** | Singular / Single-Representational | Scaled + Global | Self-Attentive / Multi-Head + Multi-Hop | Defined Transformer architecture—multi-head parallel self-attention replacing recurrence entirely. |\n",
        "| **Wallart & Frasincar (2021)** | Rotatory / Single-Level | Activated + Global | Specialized / Multi-Hop | Cyclic exchange of attention queries between textual components; exemplifies iterative refinement. |\n",
        "| **Lu (2016)** | Parallel + Co-Attention | Additive + Global | Specialized / Singular | Introduced co-attention for image–text alignment in VQA; dual modality interaction. |\n",
        "| **Yu (2017)** | Co-Attention | Additive + Global | Self-Attentive / Multi-Head | Enhances co-attention with internal self-refinement loops. |\n",
        "| **Oktay (2018)** | Singular / Multi-Representational | Additive + Global | Self-Attentive / Singular | Introduces Attention U-Net for medical segmentation; integrates attention into convolutional networks. |\n",
        "| **Wang (2019)** | Singular / Single-Level | Multiplicative + Global | Self-Attentive / Capsule-Based | Combines capsule routing and attention for dynamic part–whole reasoning. |\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Conceptual Hierarchy (Taxonomic Map)**\n",
        "```\n",
        "Attention Mechanisms\n",
        "│\n",
        "├── Feature-Related\n",
        "│ ├─ Singular\n",
        "│ ├─ Parallel\n",
        "│ ├─ Co-Attention\n",
        "│ ├─ Rotatory\n",
        "│ ├─ Hierarchical\n",
        "│ └─ Multi-Representational\n",
        "│\n",
        "├── General\n",
        "│ ├─ Scoring (Additive, Multiplicative, Scaled, Activated)\n",
        "│ ├─ Alignment (Global, Hard, Local, Reinforced)\n",
        "│ └─ Dimensionality (Single, Multi)\n",
        "│\n",
        "└── Query-Related\n",
        "├─ Type (Basic, Self-Attentive, Specialized)\n",
        "└─ Multiplicity (Singular, Multi-Head, Multi-Hop, Capsule-Based)\n",
        "```\n",
        "\n",
        "This hierarchical breakdown isolates the **axes of diversity** in attention mechanisms — structural (Feature), computational (General), and functional (Query).\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Academic Interpretation**\n",
        "\n",
        "- **Purpose:** To resolve long-standing taxonomic gaps by explicitly mapping where attention acts (*feature structure*), how it operates (*mathematical form*), and what drives it (*query formulation*).  \n",
        "- **Outcome:** Apparent diversity among models (e.g., RNN attention, co-attention, Transformer) collapses into **a unified algebraic framework** governed by three independent axes.  \n",
        "- **Contribution:** The taxonomy redefines attention not as a family of isolated architectures but as a **generalized operator for weighted relevance computation** across modalities, structures, and abstraction levels.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Final Summary**\n",
        "\n",
        "> Table 3 in Brauwers & Frasincar (2022) serves as a **taxonomic validation matrix** uniting all attention mechanisms under three orthogonal principles:\n",
        "> **(1) Feature multiplicity and representation, (2) Mathematical scoring–alignment–dimensionality core, and (3) Query type and multiplicity.**\n",
        ">\n",
        "> This multidimensional view clarifies structural and computational distinctions — for instance, *Co-Attention* (cross-modal integration) vs. *Hierarchical Attention* (intra-modal aggregation) — offering the first mathematically consistent taxonomy capable of describing the entire spectrum of attention-based architectures.\n"
      ],
      "metadata": {
        "id": "dhiQLocsiAp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparative Analysis of Core Query-Related Mechanisms**\n",
        "### *(Based on “A General Survey on Attention Mechanisms in Deep Learning,” Brauwers & Frasincar, 2022)*\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Comparative Overview Table**\n",
        "\n",
        "| **Mechanism** | **Definition (from paper context)** | **Mathematical Formulation** | **Feature–Query Relationship** | **Purpose / Functional Role** | **Representative Model(s)** |\n",
        "|:---------------|:------------------------------------|:------------------------------|:-------------------------------|:-------------------------------|:-----------------------------|\n",
        "| **Self-Attention** | The query (Q), key (K), and value (V) vectors originate from the same feature set; each element attends to all others within the same sequence. | $$\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V$$ | Intra-modal, intra-sequence. The query = feature itself. | Captures contextual dependencies between elements in one modality (e.g., words in a sentence, pixels in an image). | Vaswani et al. (2017); Yang et al. (2016) |\n",
        "| **Multi-Head Attention** | Runs multiple parallel self-attention (or cross-attention) operations with independent projections, then concatenates results. | $$\\text{MultiHead}(Q,K,V) = [\\text{head}_1, ..., \\text{head}_h]W^O,\\quad \\text{where}\\ \\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$ | Parallel intra- or inter-modal. Uses several learned subspaces. | Allows the model to attend to information from multiple representational perspectives simultaneously (syntactic, positional, semantic). | Transformer (Vaswani et al., 2017) |\n",
        "| **Masked Attention** | A restricted variant of self-attention that blocks information flow from future positions using a causal mask. | $$A = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}} + M\\right)V,\\quad M_{ij} = -\\infty \\text{ for forbidden future tokens.}$$ | Temporal intra-modal. Enforces one-way flow: each query only sees earlier elements. | Ensures autoregressive causality—used in language models and decoders to prevent “cheating.” | GPT; Transformer Decoder (Vaswani et al., 2017) |\n",
        "| **Cross-Attention** | Query originates from one modality (e.g., text), while keys/values come from another (e.g., image). | $$\\text{Attention}(Q^{(A)}, K^{(B)}, V^{(B)}) = \\text{softmax}\\left(\\frac{Q^{(A)} K^{(B)\\top}}{\\sqrt{d_k}}\\right)V^{(B)}$$ | Inter-modal (cross-domain). Query ≠ key/value source. | Enables information fusion across modalities or layers (e.g., encoder–decoder attention in translation). | Bahdanau et al. (2015); Lu et al. (2016) |\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Conceptual Distinctions**\n",
        "\n",
        "| **Dimension** | **Self-Attention** | **Multi-Head Attention** | **Masked Attention** | **Cross-Attention** |\n",
        "|:---------------|:------------------|:--------------------------|:----------------------|:----------------------|\n",
        "| **Query Source** | \\( Q = K = V \\) (same features) | \\( Q = K = V \\) but partitioned across multiple heads | \\( Q = K = V \\) | \\( Q \\neq K,V \\) (different modalities or layers) |\n",
        "| **Information Flow** | Fully bidirectional within sequence | Bidirectional, multi-representational | Unidirectional (causal) | Cross-directional (one domain → another) |\n",
        "| **Parallelism** | Single operation | Multiple independent operations combined | Single but restricted | Single per modality pair |\n",
        "| **Focus Granularity** | Learns one global context | Learns multiple parallel contexts | Learns one-step temporal context | Learns inter-modality alignment |\n",
        "| **Mathematical Control** | Softmax over all pairwise relations | Multiple softmaxes in distinct subspaces | Softmax with causal mask | Softmax between heterogeneous vector spaces |\n",
        "| **Interpretability** | Clear, easy to visualize via attention maps | Harder (many heads), but more expressive | Clear temporal causality | Clear cross-domain correspondence (e.g., text ↔ image) |\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Functional & Architectural Roles**\n",
        "\n",
        "| **Mechanism** | **Architectural Placement** | **Functional Emphasis** |\n",
        "|:---------------|:----------------------------|:--------------------------|\n",
        "| **Self-Attention** | Encoder blocks, sequence modeling layers | Global dependency modeling; replaces recurrence and convolution. |\n",
        "| **Multi-Head Attention** | Core of Transformer encoder and decoder | Captures multiple relational subspaces (semantic, syntactic, positional). |\n",
        "| **Masked Attention** | Decoder blocks of autoregressive models | Preserves causal order; ensures generative consistency in language models. |\n",
        "| **Cross-Attention** | Between encoder and decoder or across modalities | Integrates contextual information from external representations (e.g., vision–language fusion). |\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Mathematical Comparison Summary**\n",
        "\n",
        "| **Mechanism** | **Computation Equation** | **Constraint or Modification** | **Learning Impact** |\n",
        "|:----------------|:--------------------------|:-------------------------------|:---------------------|\n",
        "| **Self-Attention** | \\( A = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V \\) | None | Learns all pairwise dependencies among elements. |\n",
        "| **Multi-Head Attention** | \\( \\text{concat}(\\text{softmax}(Q_i K_i^\\top)V_i) W^O \\) | Parallel projections with shared output map | Increases representational diversity; stabilizes training. |\n",
        "| **Masked Attention** | \\( A = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}} + M\\right)V \\) | Adds mask \\( M \\) to block future tokens | Enforces sequential dependency; prevents leakage of future info. |\n",
        "| **Cross-Attention** | \\( A = \\text{softmax}\\left(\\frac{Q^{(A)} K^{(B)\\top}}{\\sqrt{d_k}}\\right)V^{(B)} \\) | Queries and keys/values from different domains | Enables encoder–decoder alignment or multimodal integration. |\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Taxonomic Placement under Brauwers & Frasincar (2022)**\n",
        "\n",
        "| **Taxonomic Axis** | **Self-Attention** | **Multi-Head** | **Masked** | **Cross-Attention** |\n",
        "|:--------------------|:------------------|:----------------|:-------------|:----------------------|\n",
        "| **Feature-Related** | Singular, single-representational | Singular, multi-representational (heads as subspaces) | Singular, single-level | Co-attention (dual modality) |\n",
        "| **General Mechanism** | Scaled scoring, global alignment | Scaled scoring, parallel global alignments | Scaled scoring + masked alignment | Scaled scoring, global alignment |\n",
        "| **Query Type** | Self-attentive | Self-attentive + multi-head multiplicity | Self-attentive + masked | Specialized (cross-modal or encoder–decoder) |\n",
        "| **Query Multiplicity** | Singular | Multi-head | Singular | Singular or multi-hop |\n",
        "| **Dimensionality** | Single or multi (variant-dependent) | Multi (per head, aggregated) | Single | Single or multi (based on modality fusion) |\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Academic Interpretation**\n",
        "\n",
        "- **Self-Attention — Core Principle:**  \n",
        "  Models full pairwise relationships within a single modality. It is mathematically symmetric, establishing the base form of attention.\n",
        "\n",
        "- **Multi-Head Attention — Representational Expansion:**  \n",
        "  Introduces *parallel subspaces*, allowing simultaneous learning of multiple relational aspects—positional, syntactic, or semantic.\n",
        "\n",
        "- **Masked Attention — Temporal Constraint:**  \n",
        "  Enforces causal unidirectionality. Used in decoders to preserve the natural sequence order essential for generation tasks.\n",
        "\n",
        "- **Cross-Attention — Modal or Layer Fusion:**  \n",
        "  Enables interactions across modalities (e.g., text ↔ image) or across network levels (e.g., encoder → decoder), serving as the bridge for context conditioning.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Conceptual Summary Diagram**\n",
        "```\n",
        "Attention Variants (Query-Related)\n",
        "│\n",
        "├── Self-Attention → Q = K = V (Intra-modal)\n",
        "│ ├── Masked → Restrict to past tokens (Causal)\n",
        "│ └── Multi-Head → Parallel attention subspaces\n",
        "│\n",
        "└── Cross-Attention → Q ≠ K,V (Inter-modal or Encoder–Decoder)\n",
        "\n",
        "```\n",
        "---\n",
        "\n",
        "## **8. Final Scholarly Insight**\n",
        "\n",
        "Within the **Query-Related dimension** of Brauwers & Frasincar’s taxonomy:\n",
        "\n",
        "* **Self-Attention** introduces the foundational intra-sequence relational mechanism.  \n",
        "* **Multi-Head Attention** increases representational capacity through multiple projection subspaces.  \n",
        "* **Masked Attention** adapts the mechanism for causal sequence generation.  \n",
        "* **Cross-Attention** generalizes attention to inter-domain and encoder–decoder communication.\n",
        "\n",
        "Together, these four mechanisms span the **entire expressive spectrum of query-related operations**, demonstrating that virtually all modern architectures—Transformers, GPT, BERT, and Vision–Language models—are **specific realizations of a single unified mathematical attention framework.**\n"
      ],
      "metadata": {
        "id": "HaRiqPcQihOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taxonomy of Attention Mechanisms (Based on Figure 3 — “A General Survey on Attention Mechanisms in Deep Learning”)**\n",
        "\n",
        "---\n",
        "\n",
        "### **Table — Taxonomic Structure**\n",
        "\n",
        "| **Category** | **Subcategory** | **Elements / Types** | **Explanation** |\n",
        "|:--------------|:----------------|:----------------------|:----------------|\n",
        "| **Feature-Related Attention** | **Multiplicity** | • Singular Features Attention<br>• Coarse-Grained Co-Attention<br>• Fine-Grained Co-Attention<br>• Multi-Grained Co-Attention<br>• Rotatory Attention ↳ (Alternating / Interactive / Parallel Co-Attention) | Governs how attention operates *across feature sets or modalities* (e.g., text ↔ image). Co-attention jointly models relevance between paired inputs. “Grained” specifies the resolution of focus, from global to local, while rotatory mechanisms cyclically alternate the direction of focus. |\n",
        "| | **Levels** | • Single-Level Attention<br>• Attention-via-Attention<br>• Hierarchical Attention | Refers to the **depth of the attention hierarchy**. Single-level applies one layer; hierarchical stacks multiple layers (e.g., word → sentence → document). Attention-via-Attention feeds the output of one attention into another, enabling meta-attention over prior focus. |\n",
        "| | **Representations** | • Single-Representational Attention<br>• Multi-Representational Attention | Determines whether focus occurs within a single embedding space or across multiple representational domains (e.g., vision + language). Enables multimodal feature fusion. |\n",
        "| **General Attention** | **Scoring** | • Additive (Bahdanau)<br>• Multiplicative (Dot-Product)<br>• Scaled Multiplicative (Vaswani)<br>• Biased / Activated / Similarity-Based | Defines *how relevance scores \\(e_l\\)* are computed between queries and keys. Additive uses an MLP; multiplicative uses inner products; scaling stabilizes gradients in high-dimensional spaces. Activated or similarity-based variants introduce nonlinearity or distance metrics. |\n",
        "| | **Alignment** | • Global / Soft Alignment<br>• Local / Hard Alignment<br>• Reinforced Alignment | Determines *which subset* of inputs are attended. Global softmax covers all positions; local restricts the window; reinforced alignment employs policy learning for discrete attention. |\n",
        "| | **Dimensionality** | • Single-Dimensional Attention<br>• Multi-Dimensional Attention | Specifies whether weighting occurs along one axis (time) or multiple (spatial, channel). Multi-dimensional forms are common in visual transformers and cross-modal architectures. |\n",
        "| **Query-Related Attention** | **Type** | • Basic Queries<br>• Specialized Queries<br>• Self-Attentive Queries | Classifies how the query (Q) is defined. Basic queries originate externally (decoder state), specialized are task-conditioned, and self-attentive derive from the same feature matrix (\\(Q=K=V\\)). |\n",
        "| | **Multiplicity** | • Singular Query Attention<br>• Multi-Head Attention<br>• Multi-Hop Attention<br>• Capsule-Based Attention | Describes the *number and interaction* of concurrent queries. Multi-head splits attention into parallel subspaces; multi-hop applies it iteratively for refinement; capsule-based introduces routing dynamics between query groups. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary Explanation**\n",
        "\n",
        "1. **Feature-Related Attention**  \n",
        "   Focuses on *what content or modality* the model attends to and how multiple inputs interact.  \n",
        "   Includes **co-attention** (mutual relevance) and **hierarchical attention** (multi-level composition).\n",
        "\n",
        "2. **General Attention**  \n",
        "   Defines the *mathematical core* — how similarity is scored, aligned, and aggregated.  \n",
        "   Unifies additive, multiplicative, and scaled formulations under one computational principle.\n",
        "\n",
        "3. **Query-Related Attention**  \n",
        "   Addresses *who attends* and *how many times*.  \n",
        "   Differentiates between self-derived, externally conditioned, or multi-query mechanisms.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conceptual Integration**\n",
        "\n",
        "| **Axis** | **Question Answered** | **Examples** |\n",
        "|:-----------|:----------------------|:--------------|\n",
        "| **Feature Axis** | *What to attend to?* | Co-attention, hierarchical attention |\n",
        "| **Computation Axis** | *How to compute relevance?* | Additive vs. multiplicative vs. scaled scoring |\n",
        "| **Query Axis** | *Who attends — and how often?* | Self-, multi-head, multi-hop |\n",
        "\n",
        "---\n",
        "\n",
        "### **Scholarly Insight**\n",
        "\n",
        "> Figure 3 in *Brauwers & Frasincar (2022)* presents a **three-dimensional taxonomy**—feature, computation, and query—that transforms attention from a collection of heuristics into a **unified mathematical framework**.  \n",
        "> It enables systematic classification of all known mechanisms—from *Bahdanau* additive alignment to *Transformer* multi-head self-attention—within a single conceptual structure.\n"
      ],
      "metadata": {
        "id": "-dumwa_57iLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Table — Works Referenced in “Related Work” Discussion**\n",
        "\n",
        "| **Author(s)** | **Year** | **Title** | **Venue** | **Connection to This Paper** |\n",
        "|:---------------|:----------|:-----------|:-----------|:------------------------------|\n",
        "| **Bahdanau, D., Cho, K., & Bengio, Y.** | 2015 | *Neural Machine Translation by Jointly Learning to Align and Translate* | ICLR | Introduced the first general neural attention mechanism for RNN-based translation; serves as the conceptual starting point of all modern attention research discussed in this survey. |\n",
        "| **Luong, M.-T., Pham, H., & Manning, C. D.** | 2015 | *Effective Approaches to Attention-based Neural Machine Translation* | EMNLP | Proposed multiplicative and global/local alignment forms of attention; forms the basis of the “general” dimension of the paper’s taxonomy. |\n",
        "| **Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R., & Bengio, Y.** | 2015 | *Show, Attend and Tell: Neural Image Caption Generation with Visual Attention* | ICML | Introduced attention in computer vision and multimodal settings; foundational for cross-modal and co-attention mechanisms categorized in the survey. |\n",
        "| **Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I.** | 2017 | *Attention Is All You Need* | NeurIPS | Proposed the Transformer architecture using multi-head self-attention; central to the paper’s query-related taxonomy dimension (self, multi-head, masked, cross-attention). |\n",
        "| **Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E.** | 2016 | *Hierarchical Attention Networks for Document Classification* | NAACL | Established hierarchical attention for multi-level feature structures; informs the paper’s “feature-level” category. |\n",
        "| **Lu, J., Yang, J., Batra, D., & Parikh, D.** | 2016 | *Hierarchical Question-Image Co-Attention for Visual Question Answering* | NeurIPS | Proposed co-attention (alternating and parallel); cornerstone of the feature multiplicity taxonomy and comparative basis for cross-modal attention analysis. |\n",
        "| **Wallart, G., & Frasincar, F.** | 2021 | *Rotatory Attention for Aspect-based Sentiment Analysis* | *Expert Systems with Applications* | Presents the “rotatory” attention mechanism, later classified under feature multiplicity in this survey’s taxonomy. |\n",
        "| **Oktay, O., Schlemper, J., Le Folgoc, L., Lee, M., Heinrich, M., Misawa, K., et al.** | 2018 | *Attention U-Net: Learning Where to Look for the Pancreas* | *arXiv preprint* | Early application of attention in medical imaging; categorized under “multi-representational attention.” |\n",
        "| **Li, J., Xiong, C., & Hoi, S. C.** | 2018 | *Learning to Attend and to Generate: Parallel and Multi-hop Attention Networks* | ACL | Example of multi-hop and parallel attention; contributes to the query multiplicity dimension of the taxonomy. |\n",
        "| **Wang, J., et al.** | 2019 | *Capsule-Based Attention Networks* | AAAI | Integrates capsule routing with attention; illustrates expansion of query multiplicity beyond standard multi-head mechanisms. |\n",
        "| **Yang, Z., He, X., Gao, J., Deng, L., & Smola, A.** | 2016 | *Hierarchical Attention for Recommender Systems* | RecSys | Demonstrates hierarchical attention outside NLP; supports the cross-domain generality of the proposed taxonomy. |\n",
        "| **Xu, K., et al.** | 2015 | *Show, Attend and Tell* | ICML | Pioneering visual attention work; underpins multi-modal attention discussion. |\n",
        "| **Itti, L., Koch, C., & Niebur, E.** | 1998 | *A Model of Saliency-Based Visual Attention for Rapid Scene Analysis* | IEEE PAMI | The earliest computational attention model in vision; included to ground modern neural attention in classical saliency theory. |\n",
        "| **Hu, J., Shen, L., & Sun, G.** | 2018 | *Squeeze-and-Excitation Networks* | CVPR | Cited as an architectural instance of attention embedded in CNNs, bridging traditional vision models and the taxonomy’s “feature-related” class. |\n",
        "| **Zhang, Y., et al.** | 2019 | *Graph Attention Networks* | ICLR | Representative of attention applied to graph-structured data; anchors the survey’s cross-domain motivation. |\n",
        "| **Li, X., et al.** | 2019 | *Attention-based Co-Representation for Medical Report Generation* | IEEE TMI | Cited as an example of co-attention in multimodal medical data; supports cross-domain generality of taxonomy. |\n",
        "| **Liu, Q., et al.** | 2018 | *Context-Aware Attention for Video Recommendation* | ACM Multimedia | Example of co-attention in recommender systems; strengthens domain diversity of attention mechanisms reviewed. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary and Scholarly Context**\n",
        "\n",
        "The *Related Work* corpus in **Brauwers & Frasincar (2022)** integrates three primary strands of the attention literature:\n",
        "\n",
        "1. **Foundational Works** — seminal contributions that define the conceptual and mathematical essence of attention:  \n",
        "   *Bahdanau (2015), Luong (2015), Vaswani (2017).*  \n",
        "   These works form the theoretical substrate for the paper’s unified framework.\n",
        "\n",
        "2. **Architectural Expansions** — research introducing **structural and functional variants** such as co-attention, hierarchical, rotatory, multi-hop, and capsule-based mechanisms.  \n",
        "   These expand the taxonomy’s *feature multiplicity* and *query multiplicity* dimensions.\n",
        "\n",
        "3. **Domain-Specific Applications** — studies extending attention beyond NLP into **vision, medical imaging, graph networks, and recommender systems.**  \n",
        "   These works demonstrate that the proposed taxonomy is **domain-agnostic** and scalable across modalities.\n",
        "\n",
        "**In Essence:**  \n",
        "The *Related Work* section positions the survey as a synthesis that unites decades of fragmented developments—from **saliency-based visual attention (Itti et al., 1998)** to **Transformer-based architectures (Vaswani et al., 2017)**—within a **coherent mathematical taxonomy** encompassing the **feature-related, general, and query-related** dimensions of modern deep learning attention.\n"
      ],
      "metadata": {
        "id": "9pqVD-AMi5kc"
      }
    }
  ]
}