{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Chronological Evolution of CNN Subfields (1900‚Äì2025)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. üß† Biological & Mathematical Foundations (1900‚Äì1970s)\n",
        "\n",
        "- 1909 ‚Äì David Hubel (born; later Nobel Prize in Medicine for visual cortex studies).  \n",
        "- 1943 ‚Äì McCulloch & Pitts: artificial neurons ‚Üí conceptual basis.  \n",
        "- 1959 ‚Äì Hubel & Wiesel (Nobel-winning research): discovery of receptive fields in the cat visual cortex ‚Üí direct inspiration for convolution filters.  \n",
        "- 1962 ‚Äì Widrow & Hoff: adaptive linear neurons (ADALINE).  \n",
        "- 1969 ‚Äì Minsky & Papert‚Äôs *Perceptrons*: critique stalls NN research until backprop is rediscovered.  \n",
        "\n",
        "---\n",
        "\n",
        "## 2. üñºÔ∏è Early CNN Concepts & Digit Recognition (1980s‚Äì1990s)\n",
        "\n",
        "- 1980 ‚Äì Fukushima: **Neocognitron** (first CNN-like model, inspired by visual cortex).  \n",
        "- 1986 ‚Äì Rumelhart et al.: backpropagation popularized.  \n",
        "- 1989 ‚Äì Yann LeCun applies CNNs + backprop to handwritten digit recognition.  \n",
        "- 1998 ‚Äì LeCun‚Äôs **LeNet-5**: convolution + subsampling layers for MNIST OCR ‚Üí seminal CNN architecture.  \n",
        "\n",
        "---\n",
        "\n",
        "## 3. üè¢ CNNs in Computer Vision Subfields (2000s‚Äì2011)\n",
        "\n",
        "- 2000s ‚Äì CNNs explored in:  \n",
        "  - Face recognition (Rowley et al.).  \n",
        "  - Traffic sign recognition (early benchmarks).  \n",
        "  - Medical imaging (early CT/MRI pattern detection).  \n",
        "- **Barriers**: limited data + computational cost. CNNs overshadowed by SVMs + handcrafted features (HOG, SIFT).  \n",
        "\n",
        "---\n",
        "\n",
        "## 4. üöÄ Deep CNN Breakthrough (2012‚Äì2014)\n",
        "\n",
        "- 2012 ‚Äì **AlexNet** (Krizhevsky, Sutskever, Hinton): ImageNet classification with GPU training ‚Üí 10√ó error reduction.  \n",
        "- 2013 ‚Äì Zeiler & Fergus visualize CNN filters.  \n",
        "- 2014 ‚Äì **VGGNet** (Simonyan & Zisserman): deep CNNs (16‚Äì19 layers).  \n",
        "- 2014 ‚Äì **GoogLeNet/Inception** (Szegedy et al.): factorized convolutions, network-in-network.  \n",
        "\n",
        "---\n",
        "\n",
        "## 5. üèõÔ∏è CNN Subfields in Vision Architectures (2015‚Äì2016)\n",
        "\n",
        "- 2015 ‚Äì **ResNet** (He et al.): residual connections solve vanishing gradient ‚Üí extremely deep CNNs (152+ layers).  \n",
        "- 2015 ‚Äì **FractalNet**: explores depth vs width scaling.  \n",
        "- 2015 ‚Äì **Fully Convolutional Networks (FCN)** for semantic segmentation (Long et al.).  \n",
        "- 2016 ‚Äì **DenseNet** (Huang et al.): dense connectivity pattern.  \n",
        "\n",
        "---\n",
        "\n",
        "## 6. üìä CNN Subfields in Specific Applications (2015‚Äì2020)\n",
        "\n",
        "**Detection**:  \n",
        "- R-CNN (2014), Fast R-CNN (2015), Faster R-CNN (2015).  \n",
        "- **YOLO** (Redmon et al., 2016): real-time object detection.  \n",
        "- **SSD** (2016): efficient detection.  \n",
        "\n",
        "**Segmentation**:  \n",
        "- **U-Net** (2015): medical imaging.  \n",
        "- **Mask R-CNN** (2017): instance segmentation.  \n",
        "\n",
        "**Generative Modeling**:  \n",
        "- **DCGAN** (2015): CNNs for adversarial image generation.  \n",
        "\n",
        "**Super-Resolution**:  \n",
        "- **SRCNN** (Dong et al., 2014).  \n",
        "\n",
        "**Video**:  \n",
        "- **C3D** (2014): 3D convolutions for spatiotemporal modeling.  \n",
        "\n",
        "---\n",
        "\n",
        "## 7. üß© CNN Hybrid Subfields (2017‚Äì2020)\n",
        "\n",
        "- **Capsule Networks (CapsNets)** (Sabour et al., 2017): attempt to fix CNN‚Äôs spatial hierarchy issues.  \n",
        "\n",
        "**Attention + CNN Hybrids**:  \n",
        "- Squeeze-and-Excitation Networks (2017).  \n",
        "- Non-local Neural Networks (2018).  \n",
        "\n",
        "**Efficient Architectures**:  \n",
        "- **MobileNet** (2017).  \n",
        "- **ShuffleNet** (2018).  \n",
        "- **EfficientNet** (Tan & Le, 2019): scaling laws for CNNs.  \n",
        "\n",
        "---\n",
        "\n",
        "## 8. ‚ö° CNN vs Transformers (2020‚Äì2025)\n",
        "\n",
        "- 2020 ‚Äì **Vision Transformer (ViT)**: CNNs challenged by pure self-attention.  \n",
        "- 2021‚Äì2022 ‚Äì Hybrid CNN+Transformer models: **ConvNeXt, CoAtNet**.  \n",
        "- 2023‚Äì2025 ‚Äì CNNs survive in efficiency-critical tasks:  \n",
        "  - Real-time mobile inference.  \n",
        "  - Low-power edge devices.  \n",
        "  - Dense prediction tasks where inductive bias (translation equivariance) still helps.  \n",
        "\n",
        "---\n",
        "\n",
        "## 9. üè• CNNs in Applied Subfields (2000‚Äì2025)\n",
        "\n",
        "- **Medical Imaging**: U-Net, 3D CNNs, CNN-RNN hybrids in radiology, pathology, genomics.  \n",
        "- **Autonomous Driving**: CNN-based perception pipelines (lane detection, obstacle detection).  \n",
        "- **Remote Sensing**: CNNs for satellite image analysis.  \n",
        "- **Video & Action Recognition**: SlowFast Networks (2019).  \n",
        "- **Art & Creativity**: CNNs in style transfer (Gatys et al., 2015).  \n",
        "\n",
        "---\n",
        "\n",
        "## üìë Conclusion\n",
        "\n",
        "The chronological evolution of CNN subfields shows a trajectory from:  \n",
        "\n",
        "**Biological inspiration (1950s‚Äì1980s) ‚Üí digit recognition (1990s) ‚Üí ImageNet revolution (2012) ‚Üí architectural innovations (2014‚Äì2019) ‚Üí application-specific CNNs (detection, segmentation, super-resolution, video) ‚Üí hybrids and Transformer competition (2020s).**  \n",
        "\n",
        "Today (2025), CNNs are no longer the dominant universal paradigm but remain crucial in **efficiency-driven, structure-sensitive, and application-specific domains**.  \n"
      ],
      "metadata": {
        "id": "iD0AJbcNIUFU"
      }
    }
  ]
}